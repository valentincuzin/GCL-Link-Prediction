{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4962e10c-1d1c-4c53-9c35-d2f18f3f8911",
   "metadata": {},
   "source": [
    "# Line Graph for embbedding Edge representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aba9794-8500-4868-a8f6-f3b520334572",
   "metadata": {},
   "source": [
    "## Some Idees to explore\n",
    "- Line Graph as embbedding for pre-training then NCN on Original Graph, Transfer Learning ??\n",
    "- Line Graph as an augmentation for contrastive learning like LGLP ?\n",
    "- Line Graph for Edge Features embbedding, but adjency Matrix fro Original Graph\n",
    "- Non-Contrastive Learning with 2 GNN one for Feature, one for Structure, then reuse theses two GNN for encoder for the final task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e42bcff-d4a2-4ab4-8848-3979811e0887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The OGB package is out of date. Your version is 1.3.5, while the latest version is 1.3.6.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from model_contrastive import Encoder, GRACE, drop_feature\n",
    "from model import CNLinkPredictor, GCN\n",
    "from NeighborOverlap import train, test\n",
    "from ogbdataset import loaddataset\n",
    "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils_contrastive import compute_pr, eigenvector_centrality\n",
    "from torch_geometric.utils import dropout_adj\n",
    "from torch_geometric.transforms import LineGraph\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from ogb.linkproppred import PygLinkPropPredDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_sparse import SparseTensor\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import train_test_split_edges, negative_sampling, to_undirected\n",
    "from torch_geometric.transforms import RandomLinkSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f16b3aa9-2dee-43b3-b8e6-a48200272722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e25769b6-5ba8-4b21-bdea-a11323e5dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = {\n",
    "    'xdp': 0.7,\n",
    "    'tdp': 0.3,\n",
    "    'pt': 0.75,\n",
    "    'gnnedp': 0.0,\n",
    "    'preedp': 0.4,\n",
    "    'predp': 0.05,\n",
    "    'gnndp': 0.05,\n",
    "    'probscale': 4.3,\n",
    "    'proboffset': 2.8,\n",
    "    'alpha': 1.0,\n",
    "    'gnnlr': 0.0043,\n",
    "    'prelr': 0.0024,\n",
    "    'batch_size': 1152,\n",
    "    'ln': True,\n",
    "    'lnnn': True,\n",
    "    'epochs': 100,\n",
    "    'runs': 1,\n",
    "    'hiddim': 256,\n",
    "    'mplayers': 1,\n",
    "    'testbs': 8192,\n",
    "    'maskinput': True,\n",
    "    'jk': True,\n",
    "    'use_xlin': True,\n",
    "    'tailact': True,\n",
    "}\n",
    "device = torch.device(f'cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ee4648c-824c-4097-9077-0e00551d2ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def legacy_train(epoch, model, predictor, data, split_edge, optimizer, evaluator, hp):\n",
    "            t1 = time.time()\n",
    "            loss = train(model, predictor, data, split_edge, optimizer,\n",
    "                         hp['batch_size'], hp['maskinput'], [], None)\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"10 train time {time.time()-t1:.2f} s, loss {loss:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc4bfe74-1aac-4a78-bcf5-af85476b6037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def legacy_test(run, epoch, model, predictor, data, split_edge, evaluator, bestscore, writer, hp):\n",
    "    t1 = time.time()\n",
    "    results, h = test(model, predictor, data, split_edge, evaluator,\n",
    "                   8192, False)\n",
    "    print(f\"test time {time.time()-t1:.2f} s\")\n",
    "    if bestscore is None:\n",
    "        bestscore = {key: list(results[key]) for key in results}\n",
    "    for key, result in results.items():\n",
    "        writer.add_scalars(f\"{key}_{run}\", {\n",
    "            \"trn\": result[0],\n",
    "            \"val\": result[1],\n",
    "            \"tst\": result[2]\n",
    "        }, epoch)\n",
    "        train_hits, valid_hits, test_hits = result\n",
    "        if valid_hits > bestscore[key][1]:\n",
    "            bestscore[key] = list(result)\n",
    "        print(key)\n",
    "        print(f'Run: {run + 1:02d}, '\n",
    "              f'Epoch: {epoch:02d}, '\n",
    "              f'Train: {100 * train_hits:.2f}%, '\n",
    "              f'Valid: {100 * valid_hits:.2f}%, '\n",
    "              f'Test: {100 * test_hits:.2f}%')\n",
    "    print('---', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9d6ce48-2538-43a4-adcb-a4b755d2c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_grace(model, data):\n",
    "    param = {\n",
    "        'learning_rate': 0.01,\n",
    "        'num_hidden': 256,\n",
    "        'num_proj_hidden': 32,\n",
    "        'activation': 'prelu',\n",
    "        'base_model': 'GCNConv',\n",
    "        'num_layers': 2,\n",
    "        'drop_edge_rate_1': 0.3,\n",
    "        'drop_edge_rate_2': 0.4,\n",
    "        'drop_feature_rate_1': 0.1,\n",
    "        'drop_feature_rate_2': 0.0,\n",
    "        'tau': 0.4,\n",
    "        'num_epochs': 3000,\n",
    "        'weight_decay': 1e-5,\n",
    "        'drop_scheme': 'degree',\n",
    "    }\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=param['learning_rate'],\n",
    "        weight_decay=param['weight_decay']\n",
    "    )\n",
    "    t1 = time.time()\n",
    "    for epoch in range(1, param['num_epochs'] + 1):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        edge_index_1 = dropout_adj(data.edge_index, p=param[f'drop_edge_rate_{1}'])[0]\n",
    "        edge_index_2 = dropout_adj(data.edge_index, p=param[f'drop_edge_rate_{2}'])[0]\n",
    "        x_1 = drop_feature(data.x, param['drop_feature_rate_1'])\n",
    "        x_2 = drop_feature(data.x, param['drop_feature_rate_2'])\n",
    "\n",
    "        z1 = model(x_1, edge_index_1)\n",
    "        z2 = model(x_2, edge_index_2)\n",
    "\n",
    "        loss = model.loss(z1, z2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'(T) | Epoch={epoch:03d}, loss={loss:.4f}')\n",
    "    print(f\"pretrain time {time.time()-t1:.2f} s, loss {loss:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef9e3c84-17ee-47ce-add8-7ad0631a1125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaddataset_line(name):\n",
    "    if name in [\"Cora\", \"Citeseer\", \"Pubmed\"]:\n",
    "        dataset = Planetoid(root=\"dataset\", name=name)\n",
    "    data = dataset[0]\n",
    "    print(data)\n",
    "    src_nodes = data.edge_index[0]\n",
    "    target_nodes = data.edge_index[1]\n",
    "    edge_attr = (\n",
    "        data.x[src_nodes] + data.x[target_nodes]\n",
    "    )  # aggregation des attributs de noeuds\n",
    "    data_c = data.clone()\n",
    "    data_c.x = edge_attr\n",
    "    line = LineGraph()(data_c)\n",
    "    line = line.to(device)\n",
    "    dataset = [line]\n",
    "    data, split_edge = loaddataset(dataset, False)\n",
    "    return data, split_edge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ncn]",
   "language": "python",
   "name": "conda-env-ncn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
