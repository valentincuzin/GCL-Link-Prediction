{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c469057-32f3-42c6-9e29-1aa96adab889",
   "metadata": {},
   "source": [
    "# GRACE as Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "44d9e7bf-a47b-449a-b959-ced94e35c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from model_contrastive import Encoder, GRACE, drop_feature\n",
    "from model import CNLinkPredictor, GCN\n",
    "from NeighborOverlap import train, test\n",
    "from ogbdataset import loaddataset, randomsplit\n",
    "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils_contrastive import compute_pr, eigenvector_centrality\n",
    "from torch_geometric.utils import dropout_adj, to_undirected, degree\n",
    "from functional_GCA import drop_edge_weighted, pr_drop_weights, degree_drop_weights, evc_drop_weights, compute_pr, eigenvector_centrality, feature_drop_weights, drop_feature_weighted_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6b436262-9ff7-4216-baa7-fe9da4005ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f4ee98bf-1089-426d-9e86-e88bb46df58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = {\n",
    "    'xdp': 0.7,\n",
    "    'tdp': 0.3,\n",
    "    'pt': 0.75,\n",
    "    'gnnedp': 0.0,\n",
    "    'preedp': 0.4,\n",
    "    'predp': 0.05,\n",
    "    'gnndp': 0.05,\n",
    "    'probscale': 4.3,\n",
    "    'proboffset': 2.8,\n",
    "    'alpha': 1.0,\n",
    "    'gnnlr': 0.0043,\n",
    "    'prelr': 0.0024,\n",
    "    'batch_size': 1152,\n",
    "    'ln': True,\n",
    "    'lnnn': True,\n",
    "    'epochs': 100,\n",
    "    'runs': 1,\n",
    "    'hiddim': 256,\n",
    "    'mplayers': 1,\n",
    "    'testbs': 8192,\n",
    "    'maskinput': True,\n",
    "    'jk': True,\n",
    "    'use_xlin': True,\n",
    "    'tailact': True,\n",
    "}\n",
    "device = torch.device(f'cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52542b48-e2be-4e11-8b7c-cef15210e56c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## legacy encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67007b76-282b-49cd-b865-46a4fd9c5a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_legacy(r, dataset, evaluator, hp):\n",
    "    writer = SummaryWriter(f\"./rec/GCN_NCN\")\n",
    "    writer.add_text(\"hyperparams\", str(hp)) \n",
    "    if dataset in [\"Cora\", \"Citeseer\", \"Pubmed\"]:\n",
    "        data, split_edge = loaddataset(dataset, False) # get a new split of dataset\n",
    "        data = data.to(device)\n",
    "    bestscore = None\n",
    "    # build model\n",
    "    model = GCN(data.num_features, hp['hiddim'], hp['hiddim'], hp['mplayers'],\n",
    "                 hp['gnndp'], hp['ln'], False, data.max_x,\n",
    "                 'puregcn', hp['jk'], hp['gnnedp'],  xdropout=hp['xdp'], taildropout=hp['tdp']).to(device)\n",
    "    predictor = CNLinkPredictor(hp['hiddim'], hp['hiddim'], 1, 3,\n",
    "                       hp['predp'], hp['preedp'], hp['lnnn']).to(device)\n",
    "    optimizer = torch.optim.Adam([{'params': model.parameters(), \"lr\": hp['gnnlr']}, \n",
    "       {'params': predictor.parameters(), 'lr': hp['prelr']}])\n",
    "    for epoch in range(1, 1 + hp['epochs']):\n",
    "        legacy_train(epoch, model, predictor, data, split_edge, optimizer, evaluator, hp)\n",
    "        if epoch % 100 == 0:\n",
    "            legacy_test(r, epoch, model, predictor, data, split_edge, evaluator, bestscore, writer, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1652abfd-2828-4a69-b2f8-2ff832a0a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def legacy_train(epoch, model, predictor, data, split_edge, optimizer, evaluator, hp):\n",
    "            t1 = time.time()\n",
    "            loss = train(model, predictor, data, split_edge, optimizer,\n",
    "                         hp['batch_size'], hp['maskinput'], [], None)\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"10 train time {time.time()-t1:.2f} s, loss {loss:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25adac93-346f-4a73-b749-7bc15dcd1caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def legacy_test(run, epoch, model, predictor, data, split_edge, evaluator, bestscore, writer, hp):\n",
    "    t1 = time.time()\n",
    "    results, h = test(model, predictor, data, split_edge, evaluator,\n",
    "                   8192, False)\n",
    "    print(f\"test time {time.time()-t1:.2f} s\")\n",
    "    if bestscore is None:\n",
    "        bestscore = {key: list(results[key]) for key in results}\n",
    "    for key, result in results.items():\n",
    "        writer.add_scalars(f\"{key}_{run}\", {\n",
    "            \"trn\": result[0],\n",
    "            \"val\": result[1],\n",
    "            \"tst\": result[2]\n",
    "        }, epoch)\n",
    "        train_hits, valid_hits, test_hits = result\n",
    "        if valid_hits > bestscore[key][1]:\n",
    "            bestscore[key] = list(result)\n",
    "        print(key)\n",
    "        print(f'Run: {run + 1:02d}, '\n",
    "              f'Epoch: {epoch:02d}, '\n",
    "              f'Train: {100 * train_hits:.2f}%, '\n",
    "              f'Valid: {100 * valid_hits:.2f}%, '\n",
    "              f'Test: {100 * test_hits:.2f}%')\n",
    "    print('---', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff439599-a6d2-4028-8fe7-4ab979bdb270",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################### Cora #################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ncn/lib/python3.10/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2708 tensor(2707)\n",
      "dataset split \n",
      "train edge 3696\n",
      "valid edge 527\n",
      "valid edge_neg 1055\n",
      "test edge 1055\n",
      "test edge_neg 1055\n",
      "10 train time 0.05 s, loss 1.1758\n",
      "10 train time 0.03 s, loss 0.8270\n",
      "10 train time 0.03 s, loss 0.7310\n",
      "10 train time 0.03 s, loss 0.7105\n",
      "10 train time 0.03 s, loss 0.6186\n",
      "10 train time 0.03 s, loss 0.6194\n",
      "10 train time 0.03 s, loss 0.6015\n",
      "10 train time 0.03 s, loss 0.5966\n",
      "10 train time 0.03 s, loss 0.5795\n",
      "10 train time 0.03 s, loss 0.5656\n",
      "test time 0.01 s\n",
      "Hits@20\n",
      "Run: 01, Epoch: 100, Train: 99.81%, Valid: 72.30%, Test: 66.35%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 100, Train: 99.95%, Valid: 84.06%, Test: 80.85%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 100, Train: 100.00%, Valid: 91.08%, Test: 88.25%\n",
      "---\n",
      "################### Citeseer #################\n",
      "3327 tensor(3325)\n",
      "dataset split \n",
      "train edge 3187\n",
      "valid edge 455\n",
      "valid edge_neg 910\n",
      "test edge 910\n",
      "test edge_neg 910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ncn/lib/python3.10/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 train time 0.02 s, loss 1.1616\n",
      "10 train time 0.02 s, loss 0.6514\n",
      "10 train time 0.03 s, loss 0.5095\n",
      "10 train time 0.03 s, loss 0.4186\n",
      "10 train time 0.03 s, loss 0.4032\n",
      "10 train time 0.02 s, loss 0.3737\n",
      "10 train time 0.03 s, loss 0.3910\n",
      "10 train time 0.02 s, loss 0.3347\n",
      "10 train time 0.05 s, loss 0.3351\n",
      "10 train time 0.04 s, loss 0.2925\n",
      "test time 0.02 s\n",
      "Hits@20\n",
      "Run: 01, Epoch: 100, Train: 100.00%, Valid: 79.12%, Test: 77.58%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 100, Train: 100.00%, Valid: 85.71%, Test: 85.49%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 100, Train: 100.00%, Valid: 92.09%, Test: 91.10%\n",
      "---\n",
      "################### Pubmed #################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ncn/lib/python3.10/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19717 tensor(19716)\n",
      "dataset split \n",
      "train edge 31028\n",
      "valid edge 4432\n",
      "valid edge_neg 8864\n",
      "test edge 8864\n",
      "test edge_neg 8864\n",
      "10 train time 0.64 s, loss 0.5941\n",
      "10 train time 0.62 s, loss 0.5149\n",
      "10 train time 0.69 s, loss 0.4916\n",
      "10 train time 0.61 s, loss 0.4602\n",
      "10 train time 0.64 s, loss 0.4486\n",
      "10 train time 0.58 s, loss 0.4398\n",
      "10 train time 0.51 s, loss 0.4409\n",
      "10 train time 0.66 s, loss 0.4347\n",
      "10 train time 0.55 s, loss 0.4298\n",
      "10 train time 0.71 s, loss 0.4264\n",
      "test time 0.17 s\n",
      "Hits@20\n",
      "Run: 01, Epoch: 100, Train: 47.86%, Valid: 43.91%, Test: 36.92%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 100, Train: 70.48%, Valid: 59.84%, Test: 59.06%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 100, Train: 85.89%, Valid: 72.50%, Test: 75.55%\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for dataset in  [\"Cora\", \"Citeseer\", \"Pubmed\"]:\n",
    "    print(f'################### {dataset} #################')\n",
    "    if dataset in [\"Cora\", \"Citeseer\", \"Pubmed\"]:\n",
    "        evaluator = Evaluator(name=f'ogbl-ppa')\n",
    "    else:\n",
    "        evaluator = Evaluator(name=f'ogbl-{args.dataset}')\n",
    "    for r in range(hp['runs']):\n",
    "        set_seed(r)\n",
    "        run_legacy(r, dataset, evaluator, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ae1dcdf-d003-42dd-abf8-7e5298b3b1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Expected input format of Evaluator for ogbl-ppa\n",
      "{'y_pred_pos': y_pred_pos, 'y_pred_neg': y_pred_neg}\n",
      "- y_pred_pos: numpy ndarray or torch tensor of shape (num_edges, ). Torch tensor on GPU is recommended for efficiency.\n",
      "- y_pred_neg: numpy ndarray or torch tensor of shape (num_edges, ). Torch tensor on GPU is recommended for efficiency.\n",
      "y_pred_pos is the predicted scores for positive edges.\n",
      "y_pred_neg is the predicted scores for negative edges.\n",
      "Note: As the evaluation metric is ranking-based, the predicted scores need to be different for different edges.\n",
      "==== Expected output format of Evaluator for ogbl-ppa\n",
      "{hits@100': hits@100}\n",
      "- hits@100 (float): Hits@100 score\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ogb.linkproppred import Evaluator\n",
    "\n",
    "evaluator = Evaluator(name = 'ogbl-ppa')\n",
    "print(evaluator.expected_input_format) \n",
    "print(evaluator.expected_output_format) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dbd03e-9b70-4e84-be8f-cfc6c7d9f645",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## GRACE encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9958a416-da50-4e1a-aabd-de7ce74e7706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grace(r, dataset, evaluator, hp):\n",
    "    writer = SummaryWriter(f\"./rec/GRACE_NCN\")\n",
    "    writer.add_text(\"hyperparams\", str(hp)) \n",
    "    if dataset in [\"Cora\", \"Citeseer\", \"Pubmed\"]:\n",
    "        data, split_edge = loaddataset(dataset, False) # get a new split of dataset\n",
    "        data = data.to(device)\n",
    "    bestscore = None\n",
    "    # build model\n",
    "    basic_encoder = Encoder(data.num_features, hp['hiddim'], nn.Identity()).to(device)\n",
    "    model = GRACE(basic_encoder, hp['hiddim'], 32).to(device)\n",
    "    pretrain_grace(model, data)\n",
    "    predictor = CNLinkPredictor(hp['hiddim'], hp['hiddim'], 1, 3,\n",
    "                       hp['predp'], hp['preedp'], hp['lnnn']).to(device)\n",
    "    optimizer = torch.optim.Adam([{'params': model.parameters(), \"lr\": hp['gnnlr']}, \n",
    "       {'params': predictor.parameters(), 'lr': hp['prelr']}])\n",
    "\n",
    "    for epoch in range(1, 1 + hp['epochs']):\n",
    "        legacy_train(epoch, model, predictor, data, split_edge, optimizer, evaluator, hp)\n",
    "        if epoch % 100 == 0:\n",
    "            legacy_test(r, epoch, model, predictor, data, split_edge, evaluator, bestscore, writer, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eae8e2be-0044-463c-ad10-bd34bf4b32b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_grace(model, data):\n",
    "    param = {\n",
    "        'learning_rate': 0.01,\n",
    "        'num_hidden': 256,\n",
    "        'num_proj_hidden': 32,\n",
    "        'activation': 'prelu',\n",
    "        'base_model': 'GCNConv',\n",
    "        'num_layers': 2,\n",
    "        'drop_edge_rate_1': 0.3,\n",
    "        'drop_edge_rate_2': 0.4,\n",
    "        'drop_feature_rate_1': 0.1,\n",
    "        'drop_feature_rate_2': 0.0,\n",
    "        'tau': 0.4,\n",
    "        'num_epochs': 3000,\n",
    "        'weight_decay': 1e-5,\n",
    "        'drop_scheme': 'degree',\n",
    "    }\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=param['learning_rate'],\n",
    "        weight_decay=param['weight_decay']\n",
    "    )\n",
    "    t1 = time.time()\n",
    "    for epoch in range(1, param['num_epochs'] + 1):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        edge_index_1 = dropout_adj(data.edge_index, p=param[f'drop_edge_rate_{1}'])[0]\n",
    "        edge_index_2 = dropout_adj(data.edge_index, p=param[f'drop_edge_rate_{2}'])[0]\n",
    "        x_1 = drop_feature(data.x, param['drop_feature_rate_1'])\n",
    "        x_2 = drop_feature(data.x, param['drop_feature_rate_2'])\n",
    "\n",
    "        z1 = model(x_1, edge_index_1)\n",
    "        z2 = model(x_2, edge_index_2)\n",
    "\n",
    "        loss = model.loss(z1, z2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'(T) | Epoch={epoch:03d}, loss={loss:.4f}')\n",
    "    print(f\"pretrain time {time.time()-t1:.2f} s, loss {loss:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97852480-2959-4c0e-b3f0-d033a838a0c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################### Cora #################\n",
      "2708 tensor(2707)\n",
      "dataset split \n",
      "train edge 3696\n",
      "valid edge 527\n",
      "valid edge_neg 1055\n",
      "test edge 1055\n",
      "test edge_neg 1055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ncn/lib/python3.10/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n",
      "/opt/conda/envs/ncn/lib/python3.10/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(T) | Epoch=010, loss=7.1178\n",
      "(T) | Epoch=020, loss=6.9902\n",
      "(T) | Epoch=030, loss=6.9279\n",
      "(T) | Epoch=040, loss=6.8804\n",
      "(T) | Epoch=050, loss=6.8625\n",
      "(T) | Epoch=060, loss=6.8371\n",
      "(T) | Epoch=070, loss=6.8243\n",
      "(T) | Epoch=080, loss=6.8099\n",
      "(T) | Epoch=090, loss=6.8018\n",
      "(T) | Epoch=100, loss=6.8029\n",
      "(T) | Epoch=110, loss=6.7826\n",
      "(T) | Epoch=120, loss=6.7881\n",
      "(T) | Epoch=130, loss=6.7815\n",
      "(T) | Epoch=140, loss=6.7715\n",
      "(T) | Epoch=150, loss=6.7691\n",
      "(T) | Epoch=160, loss=6.7640\n",
      "(T) | Epoch=170, loss=6.7614\n",
      "(T) | Epoch=180, loss=6.7596\n",
      "(T) | Epoch=190, loss=6.7603\n",
      "(T) | Epoch=200, loss=6.7551\n",
      "(T) | Epoch=210, loss=6.7554\n",
      "(T) | Epoch=220, loss=6.7496\n",
      "(T) | Epoch=230, loss=6.7556\n",
      "(T) | Epoch=240, loss=6.7525\n",
      "(T) | Epoch=250, loss=6.7502\n",
      "(T) | Epoch=260, loss=6.7436\n",
      "(T) | Epoch=270, loss=6.7434\n",
      "(T) | Epoch=280, loss=6.7474\n",
      "(T) | Epoch=290, loss=6.7436\n",
      "(T) | Epoch=300, loss=6.7416\n",
      "(T) | Epoch=310, loss=6.7439\n",
      "(T) | Epoch=320, loss=6.7392\n",
      "(T) | Epoch=330, loss=6.7390\n",
      "(T) | Epoch=340, loss=6.7431\n",
      "(T) | Epoch=350, loss=6.7408\n",
      "(T) | Epoch=360, loss=6.7398\n",
      "(T) | Epoch=370, loss=6.7454\n",
      "(T) | Epoch=380, loss=6.7376\n",
      "(T) | Epoch=390, loss=6.7376\n",
      "(T) | Epoch=400, loss=6.7371\n",
      "(T) | Epoch=410, loss=6.7450\n",
      "(T) | Epoch=420, loss=6.7408\n",
      "(T) | Epoch=430, loss=6.7450\n",
      "(T) | Epoch=440, loss=6.7388\n",
      "(T) | Epoch=450, loss=6.7380\n",
      "(T) | Epoch=460, loss=6.7383\n",
      "(T) | Epoch=470, loss=6.7402\n",
      "(T) | Epoch=480, loss=6.7368\n",
      "(T) | Epoch=490, loss=6.7432\n",
      "(T) | Epoch=500, loss=6.7394\n",
      "(T) | Epoch=510, loss=6.7431\n",
      "(T) | Epoch=520, loss=6.7388\n",
      "(T) | Epoch=530, loss=6.7356\n",
      "(T) | Epoch=540, loss=6.7405\n",
      "(T) | Epoch=550, loss=6.7457\n",
      "(T) | Epoch=560, loss=6.7385\n",
      "(T) | Epoch=570, loss=6.7379\n",
      "(T) | Epoch=580, loss=6.7329\n",
      "(T) | Epoch=590, loss=6.7387\n",
      "(T) | Epoch=600, loss=6.7436\n",
      "(T) | Epoch=610, loss=6.7359\n",
      "(T) | Epoch=620, loss=6.7353\n",
      "(T) | Epoch=630, loss=6.7446\n",
      "(T) | Epoch=640, loss=6.7441\n",
      "(T) | Epoch=650, loss=6.7383\n",
      "(T) | Epoch=660, loss=6.7395\n",
      "(T) | Epoch=670, loss=6.7395\n",
      "(T) | Epoch=680, loss=6.7380\n",
      "(T) | Epoch=690, loss=6.7392\n",
      "(T) | Epoch=700, loss=6.7331\n",
      "(T) | Epoch=710, loss=6.7307\n",
      "(T) | Epoch=720, loss=6.7401\n",
      "(T) | Epoch=730, loss=6.7369\n",
      "(T) | Epoch=740, loss=6.7386\n",
      "(T) | Epoch=750, loss=6.7397\n",
      "(T) | Epoch=760, loss=6.7434\n",
      "(T) | Epoch=770, loss=6.7425\n",
      "(T) | Epoch=780, loss=6.7386\n",
      "(T) | Epoch=790, loss=6.7389\n",
      "(T) | Epoch=800, loss=6.7337\n",
      "(T) | Epoch=810, loss=6.7385\n",
      "(T) | Epoch=820, loss=6.7391\n",
      "(T) | Epoch=830, loss=6.7382\n",
      "(T) | Epoch=840, loss=6.7424\n",
      "(T) | Epoch=850, loss=6.7418\n",
      "(T) | Epoch=860, loss=6.7413\n",
      "(T) | Epoch=870, loss=6.7366\n",
      "(T) | Epoch=880, loss=6.7385\n",
      "(T) | Epoch=890, loss=6.7369\n",
      "(T) | Epoch=900, loss=6.7388\n",
      "(T) | Epoch=910, loss=6.7364\n",
      "(T) | Epoch=920, loss=6.7424\n",
      "(T) | Epoch=930, loss=6.7308\n",
      "(T) | Epoch=940, loss=6.7363\n",
      "(T) | Epoch=950, loss=6.7403\n",
      "(T) | Epoch=960, loss=6.7382\n",
      "(T) | Epoch=970, loss=6.7332\n",
      "(T) | Epoch=980, loss=6.7362\n",
      "(T) | Epoch=990, loss=6.7348\n",
      "(T) | Epoch=1000, loss=6.7412\n",
      "(T) | Epoch=1010, loss=6.7462\n",
      "(T) | Epoch=1020, loss=6.7458\n",
      "(T) | Epoch=1030, loss=6.7420\n",
      "(T) | Epoch=1040, loss=6.7401\n",
      "(T) | Epoch=1050, loss=6.7317\n",
      "(T) | Epoch=1060, loss=6.7319\n",
      "(T) | Epoch=1070, loss=6.7350\n",
      "(T) | Epoch=1080, loss=6.7355\n",
      "(T) | Epoch=1090, loss=6.7326\n",
      "(T) | Epoch=1100, loss=6.7334\n",
      "(T) | Epoch=1110, loss=6.7363\n",
      "(T) | Epoch=1120, loss=6.7358\n",
      "(T) | Epoch=1130, loss=6.7395\n",
      "(T) | Epoch=1140, loss=6.7420\n",
      "(T) | Epoch=1150, loss=6.7393\n",
      "(T) | Epoch=1160, loss=6.7346\n",
      "(T) | Epoch=1170, loss=6.7343\n",
      "(T) | Epoch=1180, loss=6.7378\n",
      "(T) | Epoch=1190, loss=6.7388\n",
      "(T) | Epoch=1200, loss=6.7343\n",
      "(T) | Epoch=1210, loss=6.7406\n",
      "(T) | Epoch=1220, loss=6.7360\n",
      "(T) | Epoch=1230, loss=6.7341\n",
      "(T) | Epoch=1240, loss=6.7353\n",
      "(T) | Epoch=1250, loss=6.7403\n",
      "(T) | Epoch=1260, loss=6.7344\n",
      "(T) | Epoch=1270, loss=6.7445\n",
      "(T) | Epoch=1280, loss=6.7347\n",
      "(T) | Epoch=1290, loss=6.7375\n",
      "(T) | Epoch=1300, loss=6.7329\n",
      "(T) | Epoch=1310, loss=6.7370\n",
      "(T) | Epoch=1320, loss=6.7335\n",
      "(T) | Epoch=1330, loss=6.7313\n",
      "(T) | Epoch=1340, loss=6.7340\n",
      "(T) | Epoch=1350, loss=6.7319\n",
      "(T) | Epoch=1360, loss=6.7382\n",
      "(T) | Epoch=1370, loss=6.7326\n",
      "(T) | Epoch=1380, loss=6.7308\n",
      "(T) | Epoch=1390, loss=6.7352\n",
      "(T) | Epoch=1400, loss=6.7322\n",
      "(T) | Epoch=1410, loss=6.7357\n",
      "(T) | Epoch=1420, loss=6.7341\n",
      "(T) | Epoch=1430, loss=6.7304\n",
      "(T) | Epoch=1440, loss=6.7344\n",
      "(T) | Epoch=1450, loss=6.7324\n",
      "(T) | Epoch=1460, loss=6.7393\n",
      "(T) | Epoch=1470, loss=6.7386\n",
      "(T) | Epoch=1480, loss=6.7363\n",
      "(T) | Epoch=1490, loss=6.7332\n",
      "(T) | Epoch=1500, loss=6.7360\n",
      "(T) | Epoch=1510, loss=6.7342\n",
      "(T) | Epoch=1520, loss=6.7290\n",
      "(T) | Epoch=1530, loss=6.7349\n",
      "(T) | Epoch=1540, loss=6.7336\n",
      "(T) | Epoch=1550, loss=6.7351\n",
      "(T) | Epoch=1560, loss=6.7440\n",
      "(T) | Epoch=1570, loss=6.7304\n",
      "(T) | Epoch=1580, loss=6.7299\n",
      "(T) | Epoch=1590, loss=6.7337\n",
      "(T) | Epoch=1600, loss=6.7429\n",
      "(T) | Epoch=1610, loss=6.7351\n",
      "(T) | Epoch=1620, loss=6.7328\n",
      "(T) | Epoch=1630, loss=6.7316\n",
      "(T) | Epoch=1640, loss=6.7314\n",
      "(T) | Epoch=1650, loss=6.7296\n",
      "(T) | Epoch=1660, loss=6.7337\n",
      "(T) | Epoch=1670, loss=6.7311\n",
      "(T) | Epoch=1680, loss=6.7333\n",
      "(T) | Epoch=1690, loss=6.7332\n",
      "(T) | Epoch=1700, loss=6.7340\n",
      "(T) | Epoch=1710, loss=6.7275\n",
      "(T) | Epoch=1720, loss=6.7290\n",
      "(T) | Epoch=1730, loss=6.7326\n",
      "(T) | Epoch=1740, loss=6.7343\n",
      "(T) | Epoch=1750, loss=6.7270\n",
      "(T) | Epoch=1760, loss=6.7388\n",
      "(T) | Epoch=1770, loss=6.7381\n",
      "(T) | Epoch=1780, loss=6.7333\n",
      "(T) | Epoch=1790, loss=6.7296\n",
      "(T) | Epoch=1800, loss=6.7321\n",
      "(T) | Epoch=1810, loss=6.7334\n",
      "(T) | Epoch=1820, loss=6.7323\n",
      "(T) | Epoch=1830, loss=6.7353\n",
      "(T) | Epoch=1840, loss=6.7283\n",
      "(T) | Epoch=1850, loss=6.7270\n",
      "(T) | Epoch=1860, loss=6.7358\n",
      "(T) | Epoch=1870, loss=6.7304\n",
      "(T) | Epoch=1880, loss=6.7307\n",
      "(T) | Epoch=1890, loss=6.7354\n",
      "(T) | Epoch=1900, loss=6.7338\n",
      "(T) | Epoch=1910, loss=6.7362\n",
      "(T) | Epoch=1920, loss=6.7283\n",
      "(T) | Epoch=1930, loss=6.7287\n",
      "(T) | Epoch=1940, loss=6.7316\n",
      "(T) | Epoch=1950, loss=6.7325\n",
      "(T) | Epoch=1960, loss=6.7285\n",
      "(T) | Epoch=1970, loss=6.7309\n",
      "(T) | Epoch=1980, loss=6.7315\n",
      "(T) | Epoch=1990, loss=6.7305\n",
      "(T) | Epoch=2000, loss=6.7280\n",
      "(T) | Epoch=2010, loss=6.7311\n",
      "(T) | Epoch=2020, loss=6.7287\n",
      "(T) | Epoch=2030, loss=6.7320\n",
      "(T) | Epoch=2040, loss=6.7299\n",
      "(T) | Epoch=2050, loss=6.7242\n",
      "(T) | Epoch=2060, loss=6.7345\n",
      "(T) | Epoch=2070, loss=6.7296\n",
      "(T) | Epoch=2080, loss=6.7298\n",
      "(T) | Epoch=2090, loss=6.7266\n",
      "(T) | Epoch=2100, loss=6.7319\n",
      "(T) | Epoch=2110, loss=6.7323\n",
      "(T) | Epoch=2120, loss=6.7336\n",
      "(T) | Epoch=2130, loss=6.7326\n",
      "(T) | Epoch=2140, loss=6.7230\n",
      "(T) | Epoch=2150, loss=6.7289\n",
      "(T) | Epoch=2160, loss=6.7332\n",
      "(T) | Epoch=2170, loss=6.7333\n",
      "(T) | Epoch=2180, loss=6.7270\n",
      "(T) | Epoch=2190, loss=6.7333\n",
      "(T) | Epoch=2200, loss=6.7309\n",
      "(T) | Epoch=2210, loss=6.7310\n",
      "(T) | Epoch=2220, loss=6.7274\n",
      "(T) | Epoch=2230, loss=6.7314\n",
      "(T) | Epoch=2240, loss=6.7299\n",
      "(T) | Epoch=2250, loss=6.7386\n",
      "(T) | Epoch=2260, loss=6.7308\n",
      "(T) | Epoch=2270, loss=6.7324\n",
      "(T) | Epoch=2280, loss=6.7363\n",
      "(T) | Epoch=2290, loss=6.7288\n",
      "(T) | Epoch=2300, loss=6.7277\n",
      "(T) | Epoch=2310, loss=6.7335\n",
      "(T) | Epoch=2320, loss=6.7304\n",
      "(T) | Epoch=2330, loss=6.7303\n",
      "(T) | Epoch=2340, loss=6.7307\n",
      "(T) | Epoch=2350, loss=6.7276\n",
      "(T) | Epoch=2360, loss=6.7321\n",
      "(T) | Epoch=2370, loss=6.7304\n",
      "(T) | Epoch=2380, loss=6.7353\n",
      "(T) | Epoch=2390, loss=6.7284\n",
      "(T) | Epoch=2400, loss=6.7271\n",
      "(T) | Epoch=2410, loss=6.7251\n",
      "(T) | Epoch=2420, loss=6.7258\n",
      "(T) | Epoch=2430, loss=6.7260\n",
      "(T) | Epoch=2440, loss=6.7288\n",
      "(T) | Epoch=2450, loss=6.7343\n",
      "(T) | Epoch=2460, loss=6.7236\n",
      "(T) | Epoch=2470, loss=6.7286\n",
      "(T) | Epoch=2480, loss=6.7345\n",
      "(T) | Epoch=2490, loss=6.7275\n",
      "(T) | Epoch=2500, loss=6.7296\n",
      "(T) | Epoch=2510, loss=6.7264\n",
      "(T) | Epoch=2520, loss=6.7333\n",
      "(T) | Epoch=2530, loss=6.7291\n",
      "(T) | Epoch=2540, loss=6.7314\n",
      "(T) | Epoch=2550, loss=6.7307\n",
      "(T) | Epoch=2560, loss=6.7255\n",
      "(T) | Epoch=2570, loss=6.7301\n",
      "(T) | Epoch=2580, loss=6.7386\n",
      "(T) | Epoch=2590, loss=6.7261\n",
      "(T) | Epoch=2600, loss=6.7346\n",
      "(T) | Epoch=2610, loss=6.7286\n",
      "(T) | Epoch=2620, loss=6.7283\n",
      "(T) | Epoch=2630, loss=6.7269\n",
      "(T) | Epoch=2640, loss=6.7347\n",
      "(T) | Epoch=2650, loss=6.7347\n",
      "(T) | Epoch=2660, loss=6.7340\n",
      "(T) | Epoch=2670, loss=6.7314\n",
      "(T) | Epoch=2680, loss=6.7273\n",
      "(T) | Epoch=2690, loss=6.7297\n",
      "(T) | Epoch=2700, loss=6.7307\n",
      "(T) | Epoch=2710, loss=6.7305\n",
      "(T) | Epoch=2720, loss=6.7285\n",
      "(T) | Epoch=2730, loss=6.7264\n",
      "(T) | Epoch=2740, loss=6.7325\n",
      "(T) | Epoch=2750, loss=6.7274\n",
      "(T) | Epoch=2760, loss=6.7277\n",
      "(T) | Epoch=2770, loss=6.7268\n",
      "(T) | Epoch=2780, loss=6.7317\n",
      "(T) | Epoch=2790, loss=6.7265\n",
      "(T) | Epoch=2800, loss=6.7302\n",
      "(T) | Epoch=2810, loss=6.7298\n",
      "(T) | Epoch=2820, loss=6.7269\n",
      "(T) | Epoch=2830, loss=6.7259\n",
      "(T) | Epoch=2840, loss=6.7300\n",
      "(T) | Epoch=2850, loss=6.7235\n",
      "(T) | Epoch=2860, loss=6.7262\n",
      "(T) | Epoch=2870, loss=6.7250\n",
      "(T) | Epoch=2880, loss=6.7232\n",
      "(T) | Epoch=2890, loss=6.7283\n",
      "(T) | Epoch=2900, loss=6.7311\n",
      "(T) | Epoch=2910, loss=6.7253\n",
      "(T) | Epoch=2920, loss=6.7283\n",
      "(T) | Epoch=2930, loss=6.7256\n",
      "(T) | Epoch=2940, loss=6.7268\n",
      "(T) | Epoch=2950, loss=6.7265\n",
      "(T) | Epoch=2960, loss=6.7222\n",
      "(T) | Epoch=2970, loss=6.7318\n",
      "(T) | Epoch=2980, loss=6.7245\n",
      "(T) | Epoch=2990, loss=6.7278\n",
      "(T) | Epoch=3000, loss=6.7285\n",
      "10 train time 0.06 s, loss 0.2551\n",
      "10 train time 0.09 s, loss 0.1638\n",
      "10 train time 0.09 s, loss 0.1505\n",
      "10 train time 0.08 s, loss 0.1286\n",
      "10 train time 0.11 s, loss 0.1391\n",
      "10 train time 0.09 s, loss 0.1043\n",
      "10 train time 0.08 s, loss 0.1046\n",
      "10 train time 0.07 s, loss 0.0763\n",
      "10 train time 0.08 s, loss 0.0778\n",
      "10 train time 0.09 s, loss 0.0789\n",
      "test time 0.02 s\n",
      "Hits@20\n",
      "Run: 01, Epoch: 100, Train: 100.00%, Valid: 64.71%, Test: 60.19%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 100, Train: 100.00%, Valid: 74.19%, Test: 73.65%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 100, Train: 100.00%, Valid: 80.08%, Test: 80.76%\n",
      "---\n",
      "################### Citeseer #################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ncn/lib/python3.10/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3327 tensor(3325)\n",
      "dataset split \n",
      "train edge 3187\n",
      "valid edge 455\n",
      "valid edge_neg 910\n",
      "test edge 910\n",
      "test edge_neg 910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ncn/lib/python3.10/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(T) | Epoch=010, loss=7.2078\n",
      "(T) | Epoch=020, loss=7.0923\n",
      "(T) | Epoch=030, loss=7.0279\n",
      "(T) | Epoch=040, loss=6.9894\n",
      "(T) | Epoch=050, loss=6.9737\n",
      "(T) | Epoch=060, loss=6.9624\n",
      "(T) | Epoch=070, loss=6.9552\n",
      "(T) | Epoch=080, loss=6.9501\n",
      "(T) | Epoch=090, loss=6.9438\n",
      "(T) | Epoch=100, loss=6.9354\n",
      "(T) | Epoch=110, loss=6.9342\n",
      "(T) | Epoch=120, loss=6.9298\n",
      "(T) | Epoch=130, loss=6.9235\n",
      "(T) | Epoch=140, loss=6.9263\n",
      "(T) | Epoch=150, loss=6.9200\n",
      "(T) | Epoch=160, loss=6.9199\n",
      "(T) | Epoch=170, loss=6.9189\n",
      "(T) | Epoch=180, loss=6.9172\n",
      "(T) | Epoch=190, loss=6.9175\n",
      "(T) | Epoch=200, loss=6.9141\n",
      "(T) | Epoch=210, loss=6.9128\n",
      "(T) | Epoch=220, loss=6.9173\n",
      "(T) | Epoch=230, loss=6.9157\n",
      "(T) | Epoch=240, loss=6.9164\n",
      "(T) | Epoch=250, loss=6.9150\n",
      "(T) | Epoch=260, loss=6.9137\n",
      "(T) | Epoch=270, loss=6.9120\n",
      "(T) | Epoch=280, loss=6.9117\n",
      "(T) | Epoch=290, loss=6.9131\n",
      "(T) | Epoch=300, loss=6.9109\n",
      "(T) | Epoch=310, loss=6.9114\n",
      "(T) | Epoch=320, loss=6.9091\n",
      "(T) | Epoch=330, loss=6.9116\n",
      "(T) | Epoch=340, loss=6.9127\n",
      "(T) | Epoch=350, loss=6.9121\n",
      "(T) | Epoch=360, loss=6.9130\n",
      "(T) | Epoch=370, loss=6.9128\n",
      "(T) | Epoch=380, loss=6.9084\n",
      "(T) | Epoch=390, loss=6.9083\n",
      "(T) | Epoch=400, loss=6.9109\n",
      "(T) | Epoch=410, loss=6.9088\n",
      "(T) | Epoch=420, loss=6.9107\n",
      "(T) | Epoch=430, loss=6.9096\n",
      "(T) | Epoch=440, loss=6.9144\n",
      "(T) | Epoch=450, loss=6.9119\n",
      "(T) | Epoch=460, loss=6.9094\n",
      "(T) | Epoch=470, loss=6.9112\n",
      "(T) | Epoch=480, loss=6.9093\n",
      "(T) | Epoch=490, loss=6.9092\n",
      "(T) | Epoch=500, loss=6.9091\n",
      "(T) | Epoch=510, loss=6.9098\n",
      "(T) | Epoch=520, loss=6.9081\n",
      "(T) | Epoch=530, loss=6.9086\n",
      "(T) | Epoch=540, loss=6.9090\n",
      "(T) | Epoch=550, loss=6.9106\n",
      "(T) | Epoch=560, loss=6.9101\n",
      "(T) | Epoch=570, loss=6.9109\n",
      "(T) | Epoch=580, loss=6.9095\n",
      "(T) | Epoch=590, loss=6.9129\n",
      "(T) | Epoch=600, loss=6.9108\n",
      "(T) | Epoch=610, loss=6.9138\n",
      "(T) | Epoch=620, loss=6.9086\n",
      "(T) | Epoch=630, loss=6.9115\n",
      "(T) | Epoch=640, loss=6.9100\n",
      "(T) | Epoch=650, loss=6.9102\n",
      "(T) | Epoch=660, loss=6.9122\n",
      "(T) | Epoch=670, loss=6.9076\n",
      "(T) | Epoch=680, loss=6.9108\n",
      "(T) | Epoch=690, loss=6.9120\n",
      "(T) | Epoch=700, loss=6.9092\n",
      "(T) | Epoch=710, loss=6.9099\n",
      "(T) | Epoch=720, loss=6.9121\n",
      "(T) | Epoch=730, loss=6.9090\n",
      "(T) | Epoch=740, loss=6.9094\n",
      "(T) | Epoch=750, loss=6.9086\n",
      "(T) | Epoch=760, loss=6.9088\n",
      "(T) | Epoch=770, loss=6.9085\n",
      "(T) | Epoch=780, loss=6.9082\n",
      "(T) | Epoch=790, loss=6.9087\n",
      "(T) | Epoch=800, loss=6.9097\n",
      "(T) | Epoch=810, loss=6.9125\n",
      "(T) | Epoch=820, loss=6.9085\n",
      "(T) | Epoch=830, loss=6.9089\n",
      "(T) | Epoch=840, loss=6.9078\n",
      "(T) | Epoch=850, loss=6.9080\n",
      "(T) | Epoch=860, loss=6.9070\n",
      "(T) | Epoch=870, loss=6.9081\n",
      "(T) | Epoch=880, loss=6.9055\n",
      "(T) | Epoch=890, loss=6.9098\n",
      "(T) | Epoch=900, loss=6.9092\n",
      "(T) | Epoch=910, loss=6.9075\n",
      "(T) | Epoch=920, loss=6.9115\n",
      "(T) | Epoch=930, loss=6.9108\n",
      "(T) | Epoch=940, loss=6.9058\n",
      "(T) | Epoch=950, loss=6.9068\n",
      "(T) | Epoch=960, loss=6.9077\n",
      "(T) | Epoch=970, loss=6.9081\n",
      "(T) | Epoch=980, loss=6.9042\n",
      "(T) | Epoch=990, loss=6.9110\n",
      "(T) | Epoch=1000, loss=6.9063\n",
      "(T) | Epoch=1010, loss=6.9094\n",
      "(T) | Epoch=1020, loss=6.9076\n",
      "(T) | Epoch=1030, loss=6.9075\n",
      "(T) | Epoch=1040, loss=6.9074\n",
      "(T) | Epoch=1050, loss=6.9080\n",
      "(T) | Epoch=1060, loss=6.9083\n",
      "(T) | Epoch=1070, loss=6.9076\n",
      "(T) | Epoch=1080, loss=6.9065\n",
      "(T) | Epoch=1090, loss=6.9049\n",
      "(T) | Epoch=1100, loss=6.9060\n",
      "(T) | Epoch=1110, loss=6.9077\n",
      "(T) | Epoch=1120, loss=6.9072\n",
      "(T) | Epoch=1130, loss=6.9056\n",
      "(T) | Epoch=1140, loss=6.9071\n",
      "(T) | Epoch=1150, loss=6.9068\n",
      "(T) | Epoch=1160, loss=6.9079\n",
      "(T) | Epoch=1170, loss=6.9083\n",
      "(T) | Epoch=1180, loss=6.9080\n",
      "(T) | Epoch=1190, loss=6.9056\n",
      "(T) | Epoch=1200, loss=6.9066\n",
      "(T) | Epoch=1210, loss=6.9064\n",
      "(T) | Epoch=1220, loss=6.9072\n",
      "(T) | Epoch=1230, loss=6.9073\n",
      "(T) | Epoch=1240, loss=6.9042\n",
      "(T) | Epoch=1250, loss=6.9082\n",
      "(T) | Epoch=1260, loss=6.9051\n",
      "(T) | Epoch=1270, loss=6.9052\n",
      "(T) | Epoch=1280, loss=6.9058\n",
      "(T) | Epoch=1290, loss=6.9047\n",
      "(T) | Epoch=1300, loss=6.9045\n",
      "(T) | Epoch=1310, loss=6.9046\n",
      "(T) | Epoch=1320, loss=6.9054\n",
      "(T) | Epoch=1330, loss=6.9042\n",
      "(T) | Epoch=1340, loss=6.9042\n",
      "(T) | Epoch=1350, loss=6.9043\n",
      "(T) | Epoch=1360, loss=6.9055\n",
      "(T) | Epoch=1370, loss=6.9053\n",
      "(T) | Epoch=1380, loss=6.9034\n",
      "(T) | Epoch=1390, loss=6.9055\n",
      "(T) | Epoch=1400, loss=6.9064\n",
      "(T) | Epoch=1410, loss=6.9051\n",
      "(T) | Epoch=1420, loss=6.9049\n",
      "(T) | Epoch=1430, loss=6.9046\n",
      "(T) | Epoch=1440, loss=6.9067\n",
      "(T) | Epoch=1450, loss=6.9038\n",
      "(T) | Epoch=1460, loss=6.9018\n",
      "(T) | Epoch=1470, loss=6.9043\n",
      "(T) | Epoch=1480, loss=6.9051\n",
      "(T) | Epoch=1490, loss=6.9030\n",
      "(T) | Epoch=1500, loss=6.9038\n",
      "(T) | Epoch=1510, loss=6.9058\n",
      "(T) | Epoch=1520, loss=6.9054\n",
      "(T) | Epoch=1530, loss=6.9070\n",
      "(T) | Epoch=1540, loss=6.9031\n",
      "(T) | Epoch=1550, loss=6.9022\n",
      "(T) | Epoch=1560, loss=6.9058\n",
      "(T) | Epoch=1570, loss=6.9036\n",
      "(T) | Epoch=1580, loss=6.9034\n",
      "(T) | Epoch=1590, loss=6.9040\n",
      "(T) | Epoch=1600, loss=6.9047\n",
      "(T) | Epoch=1610, loss=6.9028\n",
      "(T) | Epoch=1620, loss=6.9040\n",
      "(T) | Epoch=1630, loss=6.9052\n",
      "(T) | Epoch=1640, loss=6.9037\n",
      "(T) | Epoch=1650, loss=6.9058\n",
      "(T) | Epoch=1660, loss=6.9020\n",
      "(T) | Epoch=1670, loss=6.9035\n",
      "(T) | Epoch=1680, loss=6.9040\n",
      "(T) | Epoch=1690, loss=6.9008\n",
      "(T) | Epoch=1700, loss=6.9042\n",
      "(T) | Epoch=1710, loss=6.9035\n",
      "(T) | Epoch=1720, loss=6.9021\n",
      "(T) | Epoch=1730, loss=6.9030\n",
      "(T) | Epoch=1740, loss=6.9028\n",
      "(T) | Epoch=1750, loss=6.9025\n",
      "(T) | Epoch=1760, loss=6.9029\n",
      "(T) | Epoch=1770, loss=6.9019\n",
      "(T) | Epoch=1780, loss=6.9033\n",
      "(T) | Epoch=1790, loss=6.9032\n",
      "(T) | Epoch=1800, loss=6.9030\n",
      "(T) | Epoch=1810, loss=6.9049\n",
      "(T) | Epoch=1820, loss=6.9055\n",
      "(T) | Epoch=1830, loss=6.9029\n",
      "(T) | Epoch=1840, loss=6.9028\n",
      "(T) | Epoch=1850, loss=6.9030\n",
      "(T) | Epoch=1860, loss=6.9038\n",
      "(T) | Epoch=1870, loss=6.9023\n",
      "(T) | Epoch=1880, loss=6.9029\n",
      "(T) | Epoch=1890, loss=6.9035\n",
      "(T) | Epoch=1900, loss=6.9038\n",
      "(T) | Epoch=1910, loss=6.9034\n",
      "(T) | Epoch=1920, loss=6.9029\n",
      "(T) | Epoch=1930, loss=6.9032\n",
      "(T) | Epoch=1940, loss=6.9004\n",
      "(T) | Epoch=1950, loss=6.9028\n",
      "(T) | Epoch=1960, loss=6.9009\n",
      "(T) | Epoch=1970, loss=6.9019\n",
      "(T) | Epoch=1980, loss=6.9009\n",
      "(T) | Epoch=1990, loss=6.9015\n",
      "(T) | Epoch=2000, loss=6.9017\n",
      "(T) | Epoch=2010, loss=6.9010\n",
      "(T) | Epoch=2020, loss=6.9026\n",
      "(T) | Epoch=2030, loss=6.9022\n",
      "(T) | Epoch=2040, loss=6.9012\n",
      "(T) | Epoch=2050, loss=6.9035\n",
      "(T) | Epoch=2060, loss=6.9021\n",
      "(T) | Epoch=2070, loss=6.9026\n",
      "(T) | Epoch=2080, loss=6.9016\n",
      "(T) | Epoch=2090, loss=6.8999\n",
      "(T) | Epoch=2100, loss=6.9020\n",
      "(T) | Epoch=2110, loss=6.9022\n",
      "(T) | Epoch=2120, loss=6.9017\n",
      "(T) | Epoch=2130, loss=6.9030\n",
      "(T) | Epoch=2140, loss=6.9030\n",
      "(T) | Epoch=2150, loss=6.9038\n",
      "(T) | Epoch=2160, loss=6.9017\n",
      "(T) | Epoch=2170, loss=6.9015\n",
      "(T) | Epoch=2180, loss=6.9029\n",
      "(T) | Epoch=2190, loss=6.9034\n",
      "(T) | Epoch=2200, loss=6.9030\n",
      "(T) | Epoch=2210, loss=6.9028\n",
      "(T) | Epoch=2220, loss=6.9017\n",
      "(T) | Epoch=2230, loss=6.9022\n",
      "(T) | Epoch=2240, loss=6.9018\n",
      "(T) | Epoch=2250, loss=6.9027\n",
      "(T) | Epoch=2260, loss=6.9013\n",
      "(T) | Epoch=2270, loss=6.9030\n",
      "(T) | Epoch=2280, loss=6.9021\n",
      "(T) | Epoch=2290, loss=6.9016\n",
      "(T) | Epoch=2300, loss=6.9015\n",
      "(T) | Epoch=2310, loss=6.9024\n",
      "(T) | Epoch=2320, loss=6.9034\n",
      "(T) | Epoch=2330, loss=6.9029\n",
      "(T) | Epoch=2340, loss=6.9027\n",
      "(T) | Epoch=2350, loss=6.9056\n",
      "(T) | Epoch=2360, loss=6.9044\n",
      "(T) | Epoch=2370, loss=6.9021\n",
      "(T) | Epoch=2380, loss=6.9028\n",
      "(T) | Epoch=2390, loss=6.9011\n",
      "(T) | Epoch=2400, loss=6.9018\n",
      "(T) | Epoch=2410, loss=6.9030\n",
      "(T) | Epoch=2420, loss=6.9014\n",
      "(T) | Epoch=2430, loss=6.9024\n",
      "(T) | Epoch=2440, loss=6.9008\n",
      "(T) | Epoch=2450, loss=6.9040\n",
      "(T) | Epoch=2460, loss=6.9031\n",
      "(T) | Epoch=2470, loss=6.9029\n",
      "(T) | Epoch=2480, loss=6.9026\n",
      "(T) | Epoch=2490, loss=6.9039\n",
      "(T) | Epoch=2500, loss=6.9027\n",
      "(T) | Epoch=2510, loss=6.9008\n",
      "(T) | Epoch=2520, loss=6.9042\n",
      "(T) | Epoch=2530, loss=6.9000\n",
      "(T) | Epoch=2540, loss=6.9012\n",
      "(T) | Epoch=2550, loss=6.9011\n",
      "(T) | Epoch=2560, loss=6.9016\n",
      "(T) | Epoch=2570, loss=6.9043\n",
      "(T) | Epoch=2580, loss=6.9057\n",
      "(T) | Epoch=2590, loss=6.9017\n",
      "(T) | Epoch=2600, loss=6.9017\n",
      "(T) | Epoch=2610, loss=6.9013\n",
      "(T) | Epoch=2620, loss=6.9011\n",
      "(T) | Epoch=2630, loss=6.9020\n",
      "(T) | Epoch=2640, loss=6.9013\n",
      "(T) | Epoch=2650, loss=6.9012\n",
      "(T) | Epoch=2660, loss=6.8991\n",
      "(T) | Epoch=2670, loss=6.9018\n",
      "(T) | Epoch=2680, loss=6.9012\n",
      "(T) | Epoch=2690, loss=6.9012\n",
      "(T) | Epoch=2700, loss=6.9002\n",
      "(T) | Epoch=2710, loss=6.9019\n",
      "(T) | Epoch=2720, loss=6.9031\n",
      "(T) | Epoch=2730, loss=6.9031\n",
      "(T) | Epoch=2740, loss=6.9011\n",
      "(T) | Epoch=2750, loss=6.9004\n",
      "(T) | Epoch=2760, loss=6.9021\n",
      "(T) | Epoch=2770, loss=6.9022\n",
      "(T) | Epoch=2780, loss=6.9022\n",
      "(T) | Epoch=2790, loss=6.9012\n",
      "(T) | Epoch=2800, loss=6.9038\n",
      "(T) | Epoch=2810, loss=6.9040\n",
      "(T) | Epoch=2820, loss=6.9016\n",
      "(T) | Epoch=2830, loss=6.9015\n",
      "(T) | Epoch=2840, loss=6.9019\n",
      "(T) | Epoch=2850, loss=6.9024\n",
      "(T) | Epoch=2860, loss=6.9021\n",
      "(T) | Epoch=2870, loss=6.9003\n",
      "(T) | Epoch=2880, loss=6.9008\n",
      "(T) | Epoch=2890, loss=6.9017\n",
      "(T) | Epoch=2900, loss=6.8999\n",
      "(T) | Epoch=2910, loss=6.9024\n",
      "(T) | Epoch=2920, loss=6.9024\n",
      "(T) | Epoch=2930, loss=6.9007\n",
      "(T) | Epoch=2940, loss=6.9024\n",
      "(T) | Epoch=2950, loss=6.9034\n",
      "(T) | Epoch=2960, loss=6.9003\n",
      "(T) | Epoch=2970, loss=6.9017\n",
      "(T) | Epoch=2980, loss=6.9019\n",
      "(T) | Epoch=2990, loss=6.9012\n",
      "(T) | Epoch=3000, loss=6.9025\n",
      "10 train time 0.05 s, loss 0.2858\n",
      "10 train time 0.06 s, loss 0.1071\n",
      "10 train time 0.05 s, loss 0.0756\n",
      "10 train time 0.04 s, loss 0.0654\n",
      "10 train time 0.05 s, loss 0.0625\n",
      "10 train time 0.04 s, loss 0.0733\n",
      "10 train time 0.04 s, loss 0.0477\n",
      "10 train time 0.03 s, loss 0.0485\n",
      "10 train time 0.07 s, loss 0.0341\n",
      "10 train time 0.06 s, loss 0.0524\n",
      "test time 0.02 s\n",
      "Hits@20\n",
      "Run: 01, Epoch: 100, Train: 100.00%, Valid: 67.47%, Test: 67.58%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 100, Train: 100.00%, Valid: 75.82%, Test: 79.67%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 100, Train: 100.00%, Valid: 81.98%, Test: 84.40%\n",
      "---\n",
      "################### Pubmed #################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ncn/lib/python3.10/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19717 tensor(19716)\n",
      "dataset split \n",
      "train edge 31028\n",
      "valid edge 4432\n",
      "valid edge_neg 8864\n",
      "test edge 8864\n",
      "test edge_neg 8864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ncn/lib/python3.10/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'dropout_adj' is deprecated, use 'dropout_edge' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(T) | Epoch=010, loss=9.3304\n",
      "(T) | Epoch=020, loss=9.2434\n",
      "(T) | Epoch=030, loss=9.1616\n",
      "(T) | Epoch=040, loss=9.0995\n",
      "(T) | Epoch=050, loss=9.0335\n",
      "(T) | Epoch=060, loss=9.0172\n",
      "(T) | Epoch=070, loss=8.9989\n",
      "(T) | Epoch=080, loss=8.9646\n",
      "(T) | Epoch=090, loss=8.9748\n",
      "(T) | Epoch=100, loss=8.9443\n",
      "(T) | Epoch=110, loss=8.9510\n",
      "(T) | Epoch=120, loss=8.9238\n",
      "(T) | Epoch=130, loss=8.9231\n",
      "(T) | Epoch=140, loss=8.9301\n",
      "(T) | Epoch=150, loss=8.9047\n",
      "(T) | Epoch=160, loss=8.9105\n",
      "(T) | Epoch=170, loss=8.9096\n",
      "(T) | Epoch=180, loss=8.9213\n",
      "(T) | Epoch=190, loss=8.9258\n",
      "(T) | Epoch=200, loss=8.8993\n",
      "(T) | Epoch=210, loss=8.9056\n",
      "(T) | Epoch=220, loss=8.8907\n",
      "(T) | Epoch=230, loss=8.9062\n",
      "(T) | Epoch=240, loss=8.9030\n",
      "(T) | Epoch=250, loss=8.8965\n",
      "(T) | Epoch=260, loss=8.8980\n",
      "(T) | Epoch=270, loss=8.8973\n",
      "(T) | Epoch=280, loss=8.8962\n",
      "(T) | Epoch=290, loss=8.9085\n",
      "(T) | Epoch=300, loss=8.8830\n",
      "(T) | Epoch=310, loss=8.8908\n",
      "(T) | Epoch=320, loss=8.8952\n",
      "(T) | Epoch=330, loss=8.8824\n",
      "(T) | Epoch=340, loss=8.8821\n",
      "(T) | Epoch=350, loss=8.8711\n",
      "(T) | Epoch=360, loss=8.8882\n",
      "(T) | Epoch=370, loss=8.8792\n",
      "(T) | Epoch=380, loss=8.8748\n",
      "(T) | Epoch=390, loss=8.8806\n",
      "(T) | Epoch=400, loss=8.8663\n",
      "(T) | Epoch=410, loss=8.8781\n",
      "(T) | Epoch=420, loss=8.8659\n",
      "(T) | Epoch=430, loss=8.8680\n",
      "(T) | Epoch=440, loss=8.8662\n",
      "(T) | Epoch=450, loss=8.8501\n",
      "(T) | Epoch=460, loss=8.8698\n",
      "(T) | Epoch=470, loss=8.8647\n",
      "(T) | Epoch=480, loss=8.8694\n",
      "(T) | Epoch=490, loss=8.8694\n",
      "(T) | Epoch=500, loss=8.8626\n",
      "(T) | Epoch=510, loss=8.8596\n",
      "(T) | Epoch=520, loss=8.8489\n",
      "(T) | Epoch=530, loss=8.8522\n",
      "(T) | Epoch=540, loss=8.8517\n",
      "(T) | Epoch=550, loss=8.8620\n",
      "(T) | Epoch=560, loss=8.8552\n",
      "(T) | Epoch=570, loss=8.8546\n",
      "(T) | Epoch=580, loss=8.8514\n",
      "(T) | Epoch=590, loss=8.8496\n",
      "(T) | Epoch=600, loss=8.8513\n",
      "(T) | Epoch=610, loss=8.8439\n",
      "(T) | Epoch=620, loss=8.8440\n",
      "(T) | Epoch=630, loss=8.8637\n",
      "(T) | Epoch=640, loss=8.8548\n",
      "(T) | Epoch=650, loss=8.8592\n",
      "(T) | Epoch=660, loss=8.8537\n",
      "(T) | Epoch=670, loss=8.8492\n",
      "(T) | Epoch=680, loss=8.8495\n",
      "(T) | Epoch=690, loss=8.8626\n",
      "(T) | Epoch=700, loss=8.8944\n",
      "(T) | Epoch=710, loss=8.8564\n",
      "(T) | Epoch=720, loss=8.8552\n",
      "(T) | Epoch=730, loss=8.8516\n",
      "(T) | Epoch=740, loss=8.8571\n",
      "(T) | Epoch=750, loss=8.8588\n",
      "(T) | Epoch=760, loss=8.8568\n",
      "(T) | Epoch=770, loss=8.8425\n",
      "(T) | Epoch=780, loss=8.8545\n",
      "(T) | Epoch=790, loss=8.8417\n",
      "(T) | Epoch=800, loss=8.8472\n",
      "(T) | Epoch=810, loss=8.8582\n",
      "(T) | Epoch=820, loss=8.8402\n",
      "(T) | Epoch=830, loss=8.8549\n",
      "(T) | Epoch=840, loss=8.8460\n",
      "(T) | Epoch=850, loss=8.8612\n",
      "(T) | Epoch=860, loss=8.8454\n",
      "(T) | Epoch=870, loss=8.8502\n",
      "(T) | Epoch=880, loss=8.8485\n",
      "(T) | Epoch=890, loss=8.8561\n",
      "(T) | Epoch=900, loss=8.8615\n",
      "(T) | Epoch=910, loss=8.8457\n",
      "(T) | Epoch=920, loss=8.8643\n",
      "(T) | Epoch=930, loss=8.8305\n",
      "(T) | Epoch=940, loss=8.8544\n",
      "(T) | Epoch=950, loss=8.8484\n",
      "(T) | Epoch=960, loss=8.8502\n",
      "(T) | Epoch=970, loss=8.8403\n",
      "(T) | Epoch=980, loss=8.8307\n",
      "(T) | Epoch=990, loss=8.8489\n",
      "(T) | Epoch=1000, loss=8.8381\n",
      "(T) | Epoch=1010, loss=8.8542\n",
      "(T) | Epoch=1020, loss=8.8377\n",
      "(T) | Epoch=1030, loss=8.8356\n",
      "(T) | Epoch=1040, loss=8.8423\n",
      "(T) | Epoch=1050, loss=8.8365\n",
      "(T) | Epoch=1060, loss=8.8526\n",
      "(T) | Epoch=1070, loss=8.8498\n",
      "(T) | Epoch=1080, loss=8.8537\n",
      "(T) | Epoch=1090, loss=8.8458\n",
      "(T) | Epoch=1100, loss=8.8381\n",
      "(T) | Epoch=1110, loss=8.8435\n",
      "(T) | Epoch=1120, loss=8.8373\n",
      "(T) | Epoch=1130, loss=8.8564\n",
      "(T) | Epoch=1140, loss=8.8453\n",
      "(T) | Epoch=1150, loss=8.8703\n",
      "(T) | Epoch=1160, loss=8.8504\n",
      "(T) | Epoch=1170, loss=8.8497\n",
      "(T) | Epoch=1180, loss=8.8455\n",
      "(T) | Epoch=1190, loss=8.8537\n",
      "(T) | Epoch=1200, loss=8.8340\n",
      "(T) | Epoch=1210, loss=8.8589\n",
      "(T) | Epoch=1220, loss=8.8393\n",
      "(T) | Epoch=1230, loss=8.8505\n",
      "(T) | Epoch=1240, loss=8.8369\n",
      "(T) | Epoch=1250, loss=8.8366\n",
      "(T) | Epoch=1260, loss=8.8350\n",
      "(T) | Epoch=1270, loss=8.8437\n",
      "(T) | Epoch=1280, loss=8.8380\n",
      "(T) | Epoch=1290, loss=8.8498\n",
      "(T) | Epoch=1300, loss=8.8516\n",
      "(T) | Epoch=1310, loss=8.8434\n",
      "(T) | Epoch=1320, loss=8.8458\n",
      "(T) | Epoch=1330, loss=8.8336\n",
      "(T) | Epoch=1340, loss=8.8398\n",
      "(T) | Epoch=1350, loss=8.8426\n",
      "(T) | Epoch=1360, loss=8.8493\n",
      "(T) | Epoch=1370, loss=8.8381\n",
      "(T) | Epoch=1380, loss=8.8460\n",
      "(T) | Epoch=1390, loss=8.8477\n",
      "(T) | Epoch=1400, loss=8.8376\n",
      "(T) | Epoch=1410, loss=8.8498\n",
      "(T) | Epoch=1420, loss=8.8372\n",
      "(T) | Epoch=1430, loss=8.8526\n",
      "(T) | Epoch=1440, loss=8.8402\n",
      "(T) | Epoch=1450, loss=8.8318\n",
      "(T) | Epoch=1460, loss=8.8377\n",
      "(T) | Epoch=1470, loss=8.8368\n",
      "(T) | Epoch=1480, loss=8.8375\n",
      "(T) | Epoch=1490, loss=8.8395\n",
      "(T) | Epoch=1500, loss=8.8372\n",
      "(T) | Epoch=1510, loss=8.8458\n",
      "(T) | Epoch=1520, loss=8.8454\n",
      "(T) | Epoch=1530, loss=8.8504\n",
      "(T) | Epoch=1540, loss=8.8321\n",
      "(T) | Epoch=1550, loss=8.8399\n",
      "(T) | Epoch=1560, loss=8.8448\n",
      "(T) | Epoch=1570, loss=8.8363\n",
      "(T) | Epoch=1580, loss=8.8344\n",
      "(T) | Epoch=1590, loss=8.8376\n",
      "(T) | Epoch=1600, loss=8.8401\n",
      "(T) | Epoch=1610, loss=8.8258\n",
      "(T) | Epoch=1620, loss=8.8363\n",
      "(T) | Epoch=1630, loss=8.8431\n",
      "(T) | Epoch=1640, loss=8.8423\n",
      "(T) | Epoch=1650, loss=8.8389\n",
      "(T) | Epoch=1660, loss=8.8389\n",
      "(T) | Epoch=1670, loss=8.8248\n",
      "(T) | Epoch=1680, loss=8.8337\n",
      "(T) | Epoch=1690, loss=8.8552\n",
      "(T) | Epoch=1700, loss=8.8434\n",
      "(T) | Epoch=1710, loss=8.8382\n",
      "(T) | Epoch=1720, loss=8.8416\n",
      "(T) | Epoch=1730, loss=8.8373\n",
      "(T) | Epoch=1740, loss=8.8350\n",
      "(T) | Epoch=1750, loss=8.8417\n",
      "(T) | Epoch=1760, loss=8.8363\n",
      "(T) | Epoch=1770, loss=8.8475\n",
      "(T) | Epoch=1780, loss=8.8368\n",
      "(T) | Epoch=1790, loss=8.8434\n",
      "(T) | Epoch=1800, loss=8.8503\n",
      "(T) | Epoch=1810, loss=8.8402\n",
      "(T) | Epoch=1820, loss=8.8415\n",
      "(T) | Epoch=1830, loss=8.8388\n",
      "(T) | Epoch=1840, loss=8.8456\n",
      "(T) | Epoch=1850, loss=8.8358\n",
      "(T) | Epoch=1860, loss=8.8300\n",
      "(T) | Epoch=1870, loss=8.8500\n",
      "(T) | Epoch=1880, loss=8.8309\n",
      "(T) | Epoch=1890, loss=8.8431\n",
      "(T) | Epoch=1900, loss=8.8349\n",
      "(T) | Epoch=1910, loss=8.8360\n",
      "(T) | Epoch=1920, loss=8.8255\n",
      "(T) | Epoch=1930, loss=8.8421\n",
      "(T) | Epoch=1940, loss=8.8322\n",
      "(T) | Epoch=1950, loss=8.8440\n",
      "(T) | Epoch=1960, loss=8.8487\n",
      "(T) | Epoch=1970, loss=8.8538\n",
      "(T) | Epoch=1980, loss=8.8234\n",
      "(T) | Epoch=1990, loss=8.8409\n",
      "(T) | Epoch=2000, loss=8.8190\n",
      "(T) | Epoch=2010, loss=8.8371\n",
      "(T) | Epoch=2020, loss=8.8283\n",
      "(T) | Epoch=2030, loss=8.8416\n",
      "(T) | Epoch=2040, loss=8.8409\n",
      "(T) | Epoch=2050, loss=8.8372\n",
      "(T) | Epoch=2060, loss=8.8369\n",
      "(T) | Epoch=2070, loss=8.8376\n",
      "(T) | Epoch=2080, loss=8.8331\n",
      "(T) | Epoch=2090, loss=8.8412\n",
      "(T) | Epoch=2100, loss=8.8331\n",
      "(T) | Epoch=2110, loss=8.8463\n",
      "(T) | Epoch=2120, loss=8.8447\n",
      "(T) | Epoch=2130, loss=8.8340\n",
      "(T) | Epoch=2140, loss=8.8313\n",
      "(T) | Epoch=2150, loss=8.8408\n",
      "(T) | Epoch=2160, loss=8.8260\n",
      "(T) | Epoch=2170, loss=8.8290\n",
      "(T) | Epoch=2180, loss=8.8281\n",
      "(T) | Epoch=2190, loss=8.8369\n",
      "(T) | Epoch=2200, loss=8.8358\n",
      "(T) | Epoch=2210, loss=8.8404\n",
      "(T) | Epoch=2220, loss=8.8368\n",
      "(T) | Epoch=2230, loss=8.8382\n",
      "(T) | Epoch=2240, loss=8.8257\n",
      "(T) | Epoch=2250, loss=8.8446\n",
      "(T) | Epoch=2260, loss=8.8360\n",
      "(T) | Epoch=2270, loss=8.8321\n",
      "(T) | Epoch=2280, loss=8.8454\n",
      "(T) | Epoch=2290, loss=8.8279\n",
      "(T) | Epoch=2300, loss=8.8447\n",
      "(T) | Epoch=2310, loss=8.8305\n",
      "(T) | Epoch=2320, loss=8.8287\n",
      "(T) | Epoch=2330, loss=8.8391\n",
      "(T) | Epoch=2340, loss=8.8389\n",
      "(T) | Epoch=2350, loss=8.8540\n",
      "(T) | Epoch=2360, loss=8.8423\n",
      "(T) | Epoch=2370, loss=8.8410\n",
      "(T) | Epoch=2380, loss=8.8433\n",
      "(T) | Epoch=2390, loss=8.8296\n",
      "(T) | Epoch=2400, loss=8.8373\n",
      "(T) | Epoch=2410, loss=8.8347\n",
      "(T) | Epoch=2420, loss=8.8358\n",
      "(T) | Epoch=2430, loss=8.8325\n",
      "(T) | Epoch=2440, loss=8.8355\n",
      "(T) | Epoch=2450, loss=8.8356\n",
      "(T) | Epoch=2460, loss=8.8290\n",
      "(T) | Epoch=2470, loss=8.8463\n",
      "(T) | Epoch=2480, loss=8.8363\n",
      "(T) | Epoch=2490, loss=8.8373\n",
      "(T) | Epoch=2500, loss=8.8315\n",
      "(T) | Epoch=2510, loss=8.8294\n",
      "(T) | Epoch=2520, loss=8.8305\n",
      "(T) | Epoch=2530, loss=8.8364\n",
      "(T) | Epoch=2540, loss=8.8311\n",
      "(T) | Epoch=2550, loss=8.8361\n",
      "(T) | Epoch=2560, loss=8.8308\n",
      "(T) | Epoch=2570, loss=8.8319\n",
      "(T) | Epoch=2580, loss=8.8370\n",
      "(T) | Epoch=2590, loss=8.8480\n",
      "(T) | Epoch=2600, loss=8.8296\n",
      "(T) | Epoch=2610, loss=8.8339\n",
      "(T) | Epoch=2620, loss=8.8291\n",
      "(T) | Epoch=2630, loss=8.8362\n",
      "(T) | Epoch=2640, loss=8.8217\n",
      "(T) | Epoch=2650, loss=8.8313\n",
      "(T) | Epoch=2660, loss=8.8249\n",
      "(T) | Epoch=2670, loss=8.8362\n",
      "(T) | Epoch=2680, loss=8.8253\n",
      "(T) | Epoch=2690, loss=8.8368\n",
      "(T) | Epoch=2700, loss=8.8352\n",
      "(T) | Epoch=2710, loss=8.8433\n",
      "(T) | Epoch=2720, loss=8.8416\n",
      "(T) | Epoch=2730, loss=8.8333\n",
      "(T) | Epoch=2740, loss=8.8316\n",
      "(T) | Epoch=2750, loss=8.8319\n",
      "(T) | Epoch=2760, loss=8.8355\n",
      "(T) | Epoch=2770, loss=8.8481\n",
      "(T) | Epoch=2780, loss=8.8285\n",
      "(T) | Epoch=2790, loss=8.8354\n",
      "(T) | Epoch=2800, loss=8.8477\n",
      "(T) | Epoch=2810, loss=8.8405\n",
      "(T) | Epoch=2820, loss=8.8484\n",
      "(T) | Epoch=2830, loss=8.8381\n",
      "(T) | Epoch=2840, loss=8.8339\n",
      "(T) | Epoch=2850, loss=8.8354\n",
      "(T) | Epoch=2860, loss=8.8321\n",
      "(T) | Epoch=2870, loss=8.8327\n",
      "(T) | Epoch=2880, loss=8.8377\n",
      "(T) | Epoch=2890, loss=8.8307\n",
      "(T) | Epoch=2900, loss=8.8369\n",
      "(T) | Epoch=2910, loss=8.8316\n",
      "(T) | Epoch=2920, loss=8.8395\n",
      "(T) | Epoch=2930, loss=8.8395\n",
      "(T) | Epoch=2940, loss=8.8273\n",
      "(T) | Epoch=2950, loss=8.8267\n",
      "(T) | Epoch=2960, loss=8.8215\n",
      "(T) | Epoch=2970, loss=8.8381\n",
      "(T) | Epoch=2980, loss=8.8493\n",
      "(T) | Epoch=2990, loss=8.8416\n",
      "(T) | Epoch=3000, loss=8.8370\n",
      "10 train time 0.64 s, loss 0.2171\n",
      "10 train time 0.72 s, loss 0.1668\n",
      "10 train time 0.59 s, loss 0.1477\n",
      "10 train time 0.74 s, loss 0.1289\n",
      "10 train time 0.66 s, loss 0.1303\n",
      "10 train time 0.59 s, loss 0.1149\n",
      "10 train time 0.77 s, loss 0.1089\n",
      "10 train time 0.64 s, loss 0.1041\n",
      "10 train time 0.74 s, loss 0.1014\n",
      "10 train time 0.71 s, loss 0.0928\n",
      "test time 0.04 s\n",
      "Hits@20\n",
      "Run: 01, Epoch: 100, Train: 91.67%, Valid: 49.62%, Test: 57.68%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 100, Train: 99.31%, Valid: 66.49%, Test: 68.87%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 100, Train: 99.96%, Valid: 76.17%, Test: 77.00%\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for dataset in  [\"Cora\", \"Citeseer\", \"Pubmed\"]:\n",
    "    print(f'################### {dataset} #################')\n",
    "    if dataset in [\"Cora\", \"Citeseer\", \"Pubmed\"]:\n",
    "        evaluator = Evaluator(name=f'ogbl-ppa')\n",
    "    else:\n",
    "        evaluator = Evaluator(name=f'ogbl-{args.dataset}')\n",
    "    for r in range(hp['runs']):\n",
    "        set_seed(r)\n",
    "        run_grace(r, dataset, evaluator, hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8501bb85-80b0-4c6e-a58b-f351c02e081f",
   "metadata": {},
   "source": [
    "## GRACE vs GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef6cea9-07f4-4524-b400-e296c9804ddc",
   "metadata": {},
   "source": [
    "**Cora**\n",
    "1. GCN\n",
    "```python Hits@20\n",
    "Run: 01, Epoch: 100, Train: 99.81%, Valid: 72.30%, Test: 66.35%\n",
    "Hits@50\n",
    "Run: 01, Epoch: 100, Train: 99.95%, Valid: 84.06%, Test: 80.85%\n",
    "Hits@100\n",
    "Run: 01, Epoch: 100, Train: 100.00%, Valid: 91.08%, Test: 88.25%\n",
    "```\n",
    "2. GRACE\n",
    "```python Hits@20\n",
    "Run: 01, Epoch: 100, Train: 100.00%, Valid: 64.71%, Test: 60.19%\n",
    "Hits@50\n",
    "Run: 01, Epoch: 100, Train: 100.00%, Valid: 74.19%, Test: 73.65%\n",
    "Hits@100\n",
    "Run: 01, Epoch: 100, Train: 100.00%, Valid: 80.08%, Test: 80.76%\n",
    "```\n",
    "\n",
    "**Citeseer**\n",
    "1. GCN\n",
    "```python Hits@20\n",
    "Run: 01, Epoch: 100, Train: 100.00%, Valid: 79.12%, Test: 77.58%\n",
    "Hits@50\n",
    "Run: 01, Epoch: 100, Train: 100.00%, Valid: 85.71%, Test: 85.49%\n",
    "Hits@100\n",
    "Run: 01, Epoch: 100, Train: 100.00%, Valid: 92.09%, Test: 91.10%\n",
    "  ```\n",
    "\n",
    "2. GRACE\n",
    "```python Hits@20\n",
    "Run: 01, Epoch: 100, Train: 100.00%, Valid: 67.47%, Test: 67.58%\n",
    "Hits@50\n",
    "Run: 01, Epoch: 100, Train: 100.00%, Valid: 75.82%, Test: 79.67%\n",
    "Hits@100\n",
    "Run: 01, Epoch: 100, Train: 100.00%, Valid: 81.98%, Test: 84.40%\n",
    "  ```\n",
    "\n",
    "**PubMed**\n",
    "1. GCN\n",
    "```python Hits@20\n",
    "Run: 01, Epoch: 100, Train: 47.86%, Valid: 43.91%, Test: 36.92%\n",
    "Hits@50\n",
    "Run: 01, Epoch: 100, Train: 70.48%, Valid: 59.84%, Test: 59.06%\n",
    "Hits@100\n",
    "Run: 01, Epoch: 100, Train: 85.89%, Valid: 72.50%, Test: 75.55%\n",
    "  ```\n",
    "\n",
    "3. GRACE\n",
    "```python Hits@20\n",
    "Run: 01, Epoch: 100, Train: 91.67%, Valid: 49.62%, Test: 57.68%\n",
    "Hits@50\n",
    "Run: 01, Epoch: 100, Train: 99.31%, Valid: 66.49%, Test: 68.87%\n",
    "Hits@100\n",
    "Run: 01, Epoch: 100, Train: 99.96%, Valid: 76.17%, Test: 77.00%\n",
    "```\n",
    "\n",
    "=> As we can see, GRACE encoder is worst than GCN on Cora and Citeseer, but better on PubMeb, a dense graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76103722-0844-4bda-9b5b-127dbc5e7e75",
   "metadata": {},
   "source": [
    "## GCA Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d23a76dd-c2a4-4f7c-baed-5ff9c71ba9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gca(r, dataset, evaluator, hp, drop_scheme='degree'):\n",
    "    writer = SummaryWriter(f\"./rec/GCA_NCN\")\n",
    "    writer.add_text(\"hyperparams\", str(hp)) \n",
    "    if dataset in [\"Cora\", \"Citeseer\", \"Pubmed\"]:\n",
    "        data, split_edge = loaddataset(dataset, False) # get a new split of dataset\n",
    "        data = data.to(device)\n",
    "    bestscore = None\n",
    "    # build model\n",
    "    basic_encoder = Encoder(data.num_features, hp['hiddim'], nn.Identity()).to(device)\n",
    "    model = GRACE(basic_encoder, hp['hiddim'], 32).to(device)\n",
    "    pretrain_gca(model, data, drop_scheme)\n",
    "    predictor = CNLinkPredictor(hp['hiddim'], hp['hiddim'], 1, 3,\n",
    "                       hp['predp'], hp['preedp'], hp['lnnn']).to(device)\n",
    "    optimizer = torch.optim.Adam([{'params': model.parameters(), \"lr\": hp['gnnlr']}, \n",
    "       {'params': predictor.parameters(), 'lr': hp['prelr']}])\n",
    "\n",
    "    for epoch in range(1, 1 + hp['epochs']):\n",
    "        legacy_train(epoch, model, predictor, data, split_edge, optimizer, evaluator, hp)\n",
    "        if epoch % 100 == 0:\n",
    "            legacy_test(r, epoch, model, predictor, data, split_edge, evaluator, bestscore, writer, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "65656569-6670-48cf-acd7-200ef2db32a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_gca(model, data, drop_scheme='degree'):\n",
    "    param = {\n",
    "        'learning_rate': 0.01,\n",
    "        'num_hidden': 256,\n",
    "        'num_proj_hidden': 32,\n",
    "        'activation': 'prelu',\n",
    "        'base_model': 'GCNConv',\n",
    "        'num_layers': 2,\n",
    "        'drop_edge_rate_1': 0.3,\n",
    "        'drop_edge_rate_2': 0.4,\n",
    "        'drop_feature_rate_1': 0.1,\n",
    "        'drop_feature_rate_2': 0.0,\n",
    "        'tau': 0.4,\n",
    "        'num_epochs': 3000,\n",
    "        'weight_decay': 1e-5,\n",
    "        'drop_scheme': drop_scheme,\n",
    "    }\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=param['learning_rate'],\n",
    "        weight_decay=param['weight_decay']\n",
    "    )\n",
    "\n",
    "    # compute drop_weights per centrality metrics\n",
    "    if param['drop_scheme'] == 'degree':\n",
    "        drop_weights = degree_drop_weights(data.edge_index).to(device)\n",
    "    elif param['drop_scheme'] == 'pr':\n",
    "        drop_weights = pr_drop_weights(data.edge_index, aggr='sink', k=200).to(device)\n",
    "    elif param['drop_scheme'] == 'evc':\n",
    "        drop_weights = evc_drop_weights(data).to(device)\n",
    "    else:\n",
    "        drop_weights = None\n",
    "\n",
    "    # # compute feature_weights per centrality metrics\n",
    "    if param['drop_scheme'] == 'degree':\n",
    "        edge_index_ = to_undirected(data.edge_index)\n",
    "        node_deg = degree(edge_index_[1])\n",
    "        feature_weights = feature_drop_weights(data.x, node_c=node_deg).to(device)\n",
    "    elif param['drop_scheme'] == 'pr':\n",
    "        node_pr = compute_pr(data.edge_index)\n",
    "        feature_weights = feature_drop_weights(data.x, node_c=node_pr).to(device)\n",
    "    elif param['drop_scheme'] == 'evc':\n",
    "        node_evc = eigenvector_centrality(data)\n",
    "        feature_weights = feature_drop_weights(data.x, node_c=node_evc).to(device)\n",
    "    else:\n",
    "        feature_weights = torch.ones((data.x.size(1),)).to(device)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    for epoch in range(1, param['num_epochs'] + 1):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        edge_index_1 = drop_edge_weighted(data.edge_index, drop_weights, p=param[f'drop_edge_rate_{1}'], threshold=0.7)\n",
    "        edge_index_2 = drop_edge_weighted(data.edge_index, drop_weights, p=param[f'drop_edge_rate_{2}'], threshold=0.7)\n",
    "        x_1 = drop_feature_weighted_2(data.x, feature_weights, param['drop_feature_rate_1'])\n",
    "        x_2 = drop_feature_weighted_2(data.x, feature_weights, param['drop_feature_rate_2'])\n",
    "\n",
    "        z1 = model(x_1, edge_index_1)\n",
    "        z2 = model(x_2, edge_index_2)\n",
    "\n",
    "        loss = model.loss(z1, z2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'(T) | Epoch={epoch:03d}, loss={loss:.4f}')\n",
    "    print(f\"pretrain time {time.time()-t1:.2f} s, loss {loss:.4f}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "976153cc-d830-4194-a4ef-5ecf71fa8bf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################### Citeseer #################\n",
      "3327 tensor(3325)\n",
      "dataset split \n",
      "train edge 3187\n",
      "valid edge 455\n",
      "valid edge_neg 910\n",
      "test edge 910\n",
      "test edge_neg 910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/envs/ncn/lib/python3.10/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, got 3703, 3703x3327,3326",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruns\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m      8\u001b[0m     set_seed(r)\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mrun_gca\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdegree\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[65], line 11\u001b[0m, in \u001b[0;36mrun_gca\u001b[0;34m(r, dataset, evaluator, hp, drop_scheme)\u001b[0m\n\u001b[1;32m      9\u001b[0m basic_encoder \u001b[38;5;241m=\u001b[39m Encoder(data\u001b[38;5;241m.\u001b[39mnum_features, hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhiddim\u001b[39m\u001b[38;5;124m'\u001b[39m], nn\u001b[38;5;241m.\u001b[39mIdentity())\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m GRACE(basic_encoder, hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhiddim\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m32\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mpretrain_gca\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_scheme\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m predictor \u001b[38;5;241m=\u001b[39m CNLinkPredictor(hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhiddim\u001b[39m\u001b[38;5;124m'\u001b[39m], hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhiddim\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     13\u001b[0m                    hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredp\u001b[39m\u001b[38;5;124m'\u001b[39m], hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreedp\u001b[39m\u001b[38;5;124m'\u001b[39m], hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlnnn\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam([{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgnnlr\u001b[39m\u001b[38;5;124m'\u001b[39m]}, \n\u001b[1;32m     15\u001b[0m    {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: predictor\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprelr\u001b[39m\u001b[38;5;124m'\u001b[39m]}])\n",
      "Cell \u001b[0;32mIn[66], line 38\u001b[0m, in \u001b[0;36mpretrain_gca\u001b[0;34m(model, data, drop_scheme)\u001b[0m\n\u001b[1;32m     36\u001b[0m     edge_index_ \u001b[38;5;241m=\u001b[39m to_undirected(data\u001b[38;5;241m.\u001b[39medge_index)\n\u001b[1;32m     37\u001b[0m     node_deg \u001b[38;5;241m=\u001b[39m degree(edge_index_[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 38\u001b[0m     feature_weights \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_drop_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_c\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_deg\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m param[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrop_scheme\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     40\u001b[0m     node_pr \u001b[38;5;241m=\u001b[39m compute_pr(data\u001b[38;5;241m.\u001b[39medge_index)\n",
      "File \u001b[0;32m~/GCL-Link-Prediction/NCN/functional_GCA.py:43\u001b[0m, in \u001b[0;36mfeature_drop_weights\u001b[0;34m(x, node_c)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeature_drop_weights\u001b[39m(x, node_c):\n\u001b[1;32m     42\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mbool)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 43\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnode_c\u001b[49m\n\u001b[1;32m     44\u001b[0m     w \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m.\u001b[39mlog()\n\u001b[1;32m     45\u001b[0m     s \u001b[38;5;241m=\u001b[39m (w\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m w) \u001b[38;5;241m/\u001b[39m (w\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m w\u001b[38;5;241m.\u001b[39mmean())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, got 3703, 3703x3327,3326"
     ]
    }
   ],
   "source": [
    "for dataset in  [\"Citeseer\", \"Cora\", \"Pubmed\"]:\n",
    "    print(f'################### {dataset} #################')\n",
    "    if dataset in [\"Cora\", \"Citeseer\", \"Pubmed\"]:\n",
    "        evaluator = Evaluator(name=f'ogbl-ppa')\n",
    "    else:\n",
    "        evaluator = Evaluator(name=f'ogbl-{args.dataset}')\n",
    "    for r in range(hp['runs']):\n",
    "        set_seed(r)\n",
    "        run_gca(r, dataset, evaluator, hp, 'degree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cbdd3cad-7be1-4e30-b17b-f64f3d3a8843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################### Cora #################\n",
      "2708 tensor(2707)\n",
      "dataset split \n",
      "train edge 3696\n",
      "valid edge 527\n",
      "valid edge_neg 1055\n",
      "test edge 1055\n",
      "test edge_neg 1055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/envs/ncn/lib/python3.10/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(T) | Epoch=100, loss=7.4660\n",
      "(T) | Epoch=200, loss=7.4343\n",
      "(T) | Epoch=300, loss=7.4506\n",
      "(T) | Epoch=400, loss=7.3313\n",
      "(T) | Epoch=500, loss=7.3663\n",
      "(T) | Epoch=600, loss=7.3358\n",
      "(T) | Epoch=700, loss=7.3502\n",
      "(T) | Epoch=800, loss=7.2739\n",
      "(T) | Epoch=900, loss=7.3093\n",
      "(T) | Epoch=1000, loss=7.2697\n",
      "(T) | Epoch=1100, loss=7.3093\n",
      "(T) | Epoch=1200, loss=7.2348\n",
      "(T) | Epoch=1300, loss=7.2604\n",
      "(T) | Epoch=1400, loss=7.3037\n",
      "(T) | Epoch=1500, loss=7.2455\n",
      "(T) | Epoch=1600, loss=7.2400\n",
      "(T) | Epoch=1700, loss=7.2233\n",
      "(T) | Epoch=1800, loss=7.2111\n",
      "(T) | Epoch=1900, loss=7.2442\n",
      "(T) | Epoch=2000, loss=7.2504\n",
      "(T) | Epoch=2100, loss=7.1836\n",
      "(T) | Epoch=2200, loss=7.1765\n",
      "(T) | Epoch=2300, loss=7.1965\n",
      "(T) | Epoch=2400, loss=7.2084\n",
      "(T) | Epoch=2500, loss=7.1692\n",
      "(T) | Epoch=2600, loss=7.1969\n",
      "(T) | Epoch=2700, loss=7.1868\n",
      "(T) | Epoch=2800, loss=7.1643\n",
      "(T) | Epoch=2900, loss=7.1724\n",
      "(T) | Epoch=3000, loss=7.1834\n",
      "pretrain time 45.39 s, loss 7.1834\n",
      "10 train time 0.06 s, loss 0.4126\n",
      "10 train time 0.06 s, loss 0.2851\n",
      "10 train time 0.06 s, loss 0.2462\n",
      "10 train time 0.05 s, loss 0.2166\n",
      "10 train time 0.07 s, loss 0.1754\n",
      "10 train time 0.06 s, loss 0.1540\n",
      "10 train time 0.06 s, loss 0.1174\n",
      "10 train time 0.06 s, loss 0.1362\n",
      "10 train time 0.07 s, loss 0.1425\n",
      "10 train time 0.09 s, loss 0.1036\n",
      "test time 0.02 s\n",
      "Hits@20\n",
      "Run: 01, Epoch: 100, Train: 99.97%, Valid: 62.81%, Test: 59.81%\n",
      "Hits@50\n",
      "Run: 01, Epoch: 100, Train: 99.97%, Valid: 75.71%, Test: 70.52%\n",
      "Hits@100\n",
      "Run: 01, Epoch: 100, Train: 99.97%, Valid: 82.92%, Test: 79.81%\n",
      "---\n",
      "################### Citeseer #################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/envs/ncn/lib/python3.10/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3327 tensor(3325)\n",
      "dataset split \n",
      "train edge 3187\n",
      "valid edge 455\n",
      "valid edge_neg 910\n",
      "test edge 910\n",
      "test edge_neg 910\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, got 3703, 3703x3327,3326",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruns\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m      8\u001b[0m     set_seed(r)\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mrun_gca\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[65], line 11\u001b[0m, in \u001b[0;36mrun_gca\u001b[0;34m(r, dataset, evaluator, hp, drop_scheme)\u001b[0m\n\u001b[1;32m      9\u001b[0m basic_encoder \u001b[38;5;241m=\u001b[39m Encoder(data\u001b[38;5;241m.\u001b[39mnum_features, hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhiddim\u001b[39m\u001b[38;5;124m'\u001b[39m], nn\u001b[38;5;241m.\u001b[39mIdentity())\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m GRACE(basic_encoder, hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhiddim\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m32\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mpretrain_gca\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_scheme\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m predictor \u001b[38;5;241m=\u001b[39m CNLinkPredictor(hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhiddim\u001b[39m\u001b[38;5;124m'\u001b[39m], hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhiddim\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     13\u001b[0m                    hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredp\u001b[39m\u001b[38;5;124m'\u001b[39m], hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreedp\u001b[39m\u001b[38;5;124m'\u001b[39m], hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlnnn\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam([{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgnnlr\u001b[39m\u001b[38;5;124m'\u001b[39m]}, \n\u001b[1;32m     15\u001b[0m    {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: predictor\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprelr\u001b[39m\u001b[38;5;124m'\u001b[39m]}])\n",
      "Cell \u001b[0;32mIn[66], line 41\u001b[0m, in \u001b[0;36mpretrain_gca\u001b[0;34m(model, data, drop_scheme)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m param[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrop_scheme\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     40\u001b[0m     node_pr \u001b[38;5;241m=\u001b[39m compute_pr(data\u001b[38;5;241m.\u001b[39medge_index)\n\u001b[0;32m---> 41\u001b[0m     feature_weights \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_drop_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_c\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode_pr\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m param[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrop_scheme\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     43\u001b[0m     node_evc \u001b[38;5;241m=\u001b[39m eigenvector_centrality(data)\n",
      "File \u001b[0;32m~/GCL-Link-Prediction/NCN/functional_GCA.py:43\u001b[0m, in \u001b[0;36mfeature_drop_weights\u001b[0;34m(x, node_c)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeature_drop_weights\u001b[39m(x, node_c):\n\u001b[1;32m     42\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mbool)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 43\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnode_c\u001b[49m\n\u001b[1;32m     44\u001b[0m     w \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m.\u001b[39mlog()\n\u001b[1;32m     45\u001b[0m     s \u001b[38;5;241m=\u001b[39m (w\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m w) \u001b[38;5;241m/\u001b[39m (w\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m w\u001b[38;5;241m.\u001b[39mmean())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, got 3703, 3703x3327,3326"
     ]
    }
   ],
   "source": [
    "for dataset in  [\"Cora\", \"Citeseer\", \"Pubmed\"]:\n",
    "    print(f'################### {dataset} #################')\n",
    "    if dataset in [\"Cora\", \"Citeseer\", \"Pubmed\"]:\n",
    "        evaluator = Evaluator(name=f'ogbl-ppa')\n",
    "    else:\n",
    "        evaluator = Evaluator(name=f'ogbl-{args.dataset}')\n",
    "    for r in range(hp['runs']):\n",
    "        set_seed(r)\n",
    "        run_gca(r, dataset, evaluator, hp, 'pr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617aeaa0-bfff-41aa-a340-68d784a70b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in  [\"Cora\", \"Citeseer\", \"Pubmed\"]:\n",
    "    print(f'################### {dataset} #################')\n",
    "    if dataset in [\"Cora\", \"Citeseer\", \"Pubmed\"]:\n",
    "        evaluator = Evaluator(name=f'ogbl-ppa')\n",
    "    else:\n",
    "        evaluator = Evaluator(name=f'ogbl-{args.dataset}')\n",
    "    for r in range(hp['runs']):\n",
    "        set_seed(r)\n",
    "        run_gca(r, dataset, evaluator, hp, 'pr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9931c3b-f579-4ef4-87c5-1f8b6a4aeacf",
   "metadata": {},
   "source": [
    "## BGRL encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036561a2-a69e-4f46-be53-f52c898c4697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jovyan-ncn]",
   "language": "python",
   "name": "conda-env-jovyan-ncn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
