{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1c6c6c5-4b7e-4017-8604-3834e5170a76",
   "metadata": {},
   "source": [
    "# Experiment to perform GCA on LG for LP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9074ca6-fc97-4e67-806f-ec2ad74f44d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import negative_sampling, dropout_edge\n",
    "from torch_geometric.transforms import LineGraph\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import nni\n",
    "\n",
    "from pGRACE.model import Encoder, GRACE\n",
    "from pGRACE.functional import drop_feature, drop_edge_weighted, \\\n",
    "    degree_drop_weights, \\\n",
    "    evc_drop_weights, pr_drop_weights, \\\n",
    "    feature_drop_weights, drop_feature_weighted_2, feature_drop_weights_dense\n",
    "from pGRACE.eval import log_regression, MulticlassEvaluator\n",
    "from pGRACE.utils import get_base_model, get_activation, \\\n",
    "    generate_split, compute_pr, eigenvector_centrality\n",
    "from pGRACE.dataset import get_dataset\n",
    "from torch_geometric.datasets import AttributedGraphDataset\n",
    "from torch_geometric.utils import degree, to_undirected\n",
    "from pGRACE.functional import degree_drop_weights, feature_drop_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8f08234-5b72-4256-9dc8-3e7a19c1502e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 5429], y=[2708])\n"
     ]
    }
   ],
   "source": [
    "attr_graph_dataset = AttributedGraphDataset(\"./dataset\", \"Cora\")\n",
    "cora = attr_graph_dataset[0]\n",
    "print(cora)\n",
    "G = cora\n",
    "dataset = attr_graph_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc93c92c-403f-4e3b-aeec-f1768c6bd50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_negative_edges(edge_index, num_nodes):\n",
    "    adj_matrix = torch.zeros((num_nodes, num_nodes), dtype=torch.bool)\n",
    "    adj_matrix[edge_index[0], edge_index[1]] = True\n",
    "    neg_edge_index = torch.nonzero(~adj_matrix, as_tuple=False).t()\n",
    "\n",
    "    return neg_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e74d8ab-6f97-4141-94eb-cd9d76a9fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_linegraph(graph: Data):\n",
    "    graph_c = graph.clone()\n",
    "    num_edges = graph_c.num_edges\n",
    "    # on construit le line graph_c avec 50% de negative edge et 50% de positive edge\n",
    "    #Â on essaie de garder le nombre total de edge identique\n",
    "    neg_edge_index = all_negative_edges(graph_c.ed\n",
    "    graph_c.edge_index = torch.cat((pos_edge_index, neg_edge_index), -1)\n",
    "    num_edges = graph_c.num_edges\n",
    "    src_nodes = graph_c.edge_index[0]\n",
    "    target_nodes = graph_c.edge_index[1]\n",
    "    edge_attr = (\n",
    "        graph_c.x[src_nodes] + graph_c.x[target_nodes]\n",
    "    )  # aggregation des attributs de noeuds\n",
    "    graph_c.edge_attr = edge_attr\n",
    "    linegraph = LineGraph()(graph_c)\n",
    "    edge_index_ = to_undirected(linegraph.edge_index)\n",
    "    node_deg = degree(edge_index_[1])\n",
    "    # print(node_deg.shape[0], linegraph.x.shape[0])\n",
    "    if node_deg.shape[0] != linegraph.x.shape[0]:\n",
    "        # print('aie')\n",
    "        return to_linegraph(graph)\n",
    "    linegraph.y = torch.tensor(\n",
    "        np.concatenate((np.ones(pos_edge_index.size(1)), np.zeros(neg_edge_index.size(1)))), dtype=torch.int64\n",
    "    )  # label la moitier son vrai, l'autre neg\n",
    "    # print(linegraph)\n",
    "    return linegraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde5a5c-21c2-4f37-8afb-02cd35246cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LG = to_linegraph(G)\n",
    "LG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d49d557f-28ee-479f-97f7-a673a5ff203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_hidden\": 256,\n",
    "    \"num_proj_hidden\": 32,\n",
    "    \"activation\": \"prelu\",\n",
    "    \"base_model\": \"GCNConv\",\n",
    "    \"num_layers\": 2,\n",
    "    \"drop_edge_rate_1\": 0.3,\n",
    "    \"drop_edge_rate_2\": 0.4,\n",
    "    \"drop_feature_rate_1\": 0.1,\n",
    "    \"drop_feature_rate_2\": 0.0,\n",
    "    \"tau\": 0.4,\n",
    "    \"num_epochs\": 3000,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"drop_scheme\": \"degree\",\n",
    "}\n",
    "device = 'cuda:0'\n",
    "torch.manual_seed(12345)\n",
    "device = torch.device(device)\n",
    "random.seed(12345)\n",
    "data = LG.to(device)\n",
    "\n",
    "split = generate_split(\n",
    "    data.num_nodes, train_ratio=0.1, val_ratio=0.1\n",
    ")  # generic train test split\n",
    "\n",
    "encoder = Encoder(\n",
    "    len(data.x[1]),\n",
    "    param[\"num_hidden\"],\n",
    "    get_activation(param[\"activation\"]),\n",
    "    base_model=get_base_model(param[\"base_model\"]),\n",
    "    k=param[\"num_layers\"],\n",
    ").to(device)\n",
    "\n",
    "model = GRACE(\n",
    "    encoder, param[\"num_hidden\"], param[\"num_proj_hidden\"], param[\"tau\"]\n",
    ").to(device)  # init the model\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=param[\"learning_rate\"], weight_decay=param[\"weight_decay\"]\n",
    ")\n",
    "\n",
    "drop_weights = degree_drop_weights(data.edge_index).to(device)\n",
    "edge_index_ = to_undirected(data.edge_index)\n",
    "node_deg = degree(edge_index_[1])\n",
    "feature_weights = feature_drop_weights(data.x, node_c=node_deg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c92f7b9f-2707-4636-aa33-71d6deb4a226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    def drop_edge(idx: int):\n",
    "        \n",
    "        if param['drop_scheme'] == 'uniform':\n",
    "            return dropout_adj(data.edge_index, p=param[f'drop_edge_rate_{idx}'])[0]\n",
    "        elif param['drop_scheme'] in ['degree', 'evc', 'pr']:\n",
    "            return drop_edge_weighted(data.edge_index, drop_weights, p=param[f'drop_edge_rate_{idx}'], threshold=0.7)\n",
    "        else:\n",
    "            raise Exception(f'undefined drop scheme: {param[\"drop_scheme\"]}')\n",
    "\n",
    "    edge_index_1 = drop_edge(1)\n",
    "    edge_index_2 = drop_edge(2)\n",
    "    x_1 = drop_feature(data.x, param['drop_feature_rate_1'])\n",
    "    x_2 = drop_feature(data.x, param['drop_feature_rate_2'])\n",
    "\n",
    "    if param['drop_scheme'] in ['pr', 'degree', 'evc']:\n",
    "        x_1 = drop_feature_weighted_2(data.x, feature_weights, param['drop_feature_rate_1'])\n",
    "        x_2 = drop_feature_weighted_2(data.x, feature_weights, param['drop_feature_rate_2'])\n",
    "\n",
    "    z1 = model(x_1, edge_index_1)\n",
    "    z2 = model(x_2, edge_index_2)\n",
    "\n",
    "    loss = model.loss(z1, z2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d45da1e7-29de-4a03-bf10-e9dcb26748f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(final=False):\n",
    "    model.eval()\n",
    "    \n",
    "    z = model(data.x, data.edge_index)\n",
    "    z = z.to(device)\n",
    "\n",
    "    evaluator = MulticlassEvaluator()\n",
    "    acc = log_regression(z, data, evaluator, split='rand:0.1', num_epochs=3000, preload_split=split)['acc']\n",
    "\n",
    "    if final:\n",
    "        nni.report_final_result(acc)\n",
    "    else:\n",
    "        nni.report_intermediate_result(acc)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58aa2560-6e91-4ab4-b07c-609c2eca1f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(T) | Epoch=010, loss=9.2902\n",
      "(T) | Epoch=020, loss=9.1153\n",
      "(T) | Epoch=030, loss=9.0941\n",
      "(T) | Epoch=040, loss=8.9735\n",
      "(T) | Epoch=050, loss=8.9161\n",
      "(T) | Epoch=060, loss=8.8862\n",
      "(T) | Epoch=070, loss=8.7450\n",
      "(T) | Epoch=080, loss=8.6569\n",
      "(T) | Epoch=090, loss=8.7053\n",
      "(T) | Epoch=100, loss=8.6950\n",
      "[2025-02-21 13:37:54] \u001b[32mIntermediate result: 0.593317985534668  (Index 4)\u001b[0m\n",
      "(E) | Epoch=0100, avg_acc = 0.593317985534668\n",
      "(T) | Epoch=110, loss=8.6775\n",
      "(T) | Epoch=120, loss=8.5511\n",
      "(T) | Epoch=130, loss=8.4888\n",
      "(T) | Epoch=140, loss=8.4160\n",
      "(T) | Epoch=150, loss=8.3984\n",
      "(T) | Epoch=160, loss=8.3025\n",
      "(T) | Epoch=170, loss=8.3841\n",
      "(T) | Epoch=180, loss=8.2801\n",
      "(T) | Epoch=190, loss=8.2963\n",
      "(T) | Epoch=200, loss=8.2268\n",
      "[2025-02-21 13:38:01] \u001b[32mIntermediate result: 0.6172811388969421  (Index 5)\u001b[0m\n",
      "(E) | Epoch=0200, avg_acc = 0.6172811388969421\n",
      "(T) | Epoch=210, loss=8.1852\n",
      "(T) | Epoch=220, loss=8.1453\n",
      "(T) | Epoch=230, loss=8.1763\n",
      "(T) | Epoch=240, loss=8.1283\n",
      "(T) | Epoch=250, loss=8.1400\n",
      "(T) | Epoch=260, loss=8.0421\n",
      "(T) | Epoch=270, loss=8.0800\n",
      "(T) | Epoch=280, loss=8.0062\n",
      "(T) | Epoch=290, loss=8.0217\n",
      "(T) | Epoch=300, loss=8.0105\n",
      "[2025-02-21 13:38:09] \u001b[32mIntermediate result: 0.6276497840881348  (Index 6)\u001b[0m\n",
      "(E) | Epoch=0300, avg_acc = 0.6276497840881348\n",
      "(T) | Epoch=310, loss=7.9817\n",
      "(T) | Epoch=320, loss=7.9455\n",
      "(T) | Epoch=330, loss=7.9140\n",
      "(T) | Epoch=340, loss=7.8854\n",
      "(T) | Epoch=350, loss=7.8885\n",
      "(T) | Epoch=360, loss=7.9045\n",
      "(T) | Epoch=370, loss=7.9576\n",
      "(T) | Epoch=380, loss=7.8658\n",
      "(T) | Epoch=390, loss=7.8632\n",
      "(T) | Epoch=400, loss=7.7996\n",
      "[2025-02-21 13:38:16] \u001b[32mIntermediate result: 0.613364040851593  (Index 7)\u001b[0m\n",
      "(E) | Epoch=0400, avg_acc = 0.613364040851593\n",
      "(T) | Epoch=410, loss=7.8119\n",
      "(T) | Epoch=420, loss=7.8186\n",
      "(T) | Epoch=430, loss=7.8176\n",
      "(T) | Epoch=440, loss=7.7958\n",
      "(T) | Epoch=450, loss=7.7630\n",
      "(T) | Epoch=460, loss=7.8035\n",
      "(T) | Epoch=470, loss=7.7677\n",
      "(T) | Epoch=480, loss=7.7244\n",
      "(T) | Epoch=490, loss=7.7412\n",
      "(T) | Epoch=500, loss=7.7603\n",
      "[2025-02-21 13:38:24] \u001b[32mIntermediate result: 0.6179723739624023  (Index 8)\u001b[0m\n",
      "(E) | Epoch=0500, avg_acc = 0.6179723739624023\n",
      "(T) | Epoch=510, loss=7.7447\n",
      "(T) | Epoch=520, loss=7.7223\n",
      "(T) | Epoch=530, loss=7.7058\n",
      "(T) | Epoch=540, loss=7.6691\n",
      "(T) | Epoch=550, loss=7.7105\n",
      "(T) | Epoch=560, loss=7.7214\n",
      "(T) | Epoch=570, loss=7.6600\n",
      "(T) | Epoch=580, loss=7.6648\n",
      "(T) | Epoch=590, loss=7.6807\n",
      "(T) | Epoch=600, loss=7.7100\n",
      "[2025-02-21 13:38:31] \u001b[32mIntermediate result: 0.6062211990356445  (Index 9)\u001b[0m\n",
      "(E) | Epoch=0600, avg_acc = 0.6062211990356445\n",
      "(T) | Epoch=610, loss=7.6591\n",
      "(T) | Epoch=620, loss=7.6831\n",
      "(T) | Epoch=630, loss=7.6468\n",
      "(T) | Epoch=640, loss=7.6266\n",
      "(T) | Epoch=650, loss=7.6504\n",
      "(T) | Epoch=660, loss=7.6381\n",
      "(T) | Epoch=670, loss=7.6893\n",
      "(T) | Epoch=680, loss=7.5800\n",
      "(T) | Epoch=690, loss=7.6330\n",
      "(T) | Epoch=700, loss=7.5884\n",
      "[2025-02-21 13:38:39] \u001b[32mIntermediate result: 0.6071428656578064  (Index 10)\u001b[0m\n",
      "(E) | Epoch=0700, avg_acc = 0.6071428656578064\n",
      "(T) | Epoch=710, loss=7.5675\n",
      "(T) | Epoch=720, loss=7.5825\n",
      "(T) | Epoch=730, loss=7.5920\n",
      "(T) | Epoch=740, loss=7.5975\n",
      "(T) | Epoch=750, loss=7.5957\n",
      "(T) | Epoch=760, loss=7.5863\n",
      "(T) | Epoch=770, loss=7.5611\n",
      "(T) | Epoch=780, loss=7.5783\n",
      "(T) | Epoch=790, loss=7.5735\n",
      "(T) | Epoch=800, loss=7.6197\n",
      "[2025-02-21 13:38:46] \u001b[32mIntermediate result: 0.6080645322799683  (Index 11)\u001b[0m\n",
      "(E) | Epoch=0800, avg_acc = 0.6080645322799683\n",
      "(T) | Epoch=810, loss=7.5634\n",
      "(T) | Epoch=820, loss=7.5400\n",
      "(T) | Epoch=830, loss=7.5154\n",
      "(T) | Epoch=840, loss=7.5611\n",
      "(T) | Epoch=850, loss=7.5554\n",
      "(T) | Epoch=860, loss=7.5759\n",
      "(T) | Epoch=870, loss=7.5879\n",
      "(T) | Epoch=880, loss=7.5488\n",
      "(T) | Epoch=890, loss=7.5359\n",
      "(T) | Epoch=900, loss=7.5510\n",
      "[2025-02-21 13:38:54] \u001b[32mIntermediate result: 0.6129032373428345  (Index 12)\u001b[0m\n",
      "(E) | Epoch=0900, avg_acc = 0.6129032373428345\n",
      "(T) | Epoch=910, loss=7.5271\n",
      "(T) | Epoch=920, loss=7.5296\n",
      "(T) | Epoch=930, loss=7.5058\n",
      "(T) | Epoch=940, loss=7.5648\n",
      "(T) | Epoch=950, loss=7.5188\n",
      "(T) | Epoch=960, loss=7.4849\n",
      "(T) | Epoch=970, loss=7.5148\n",
      "(T) | Epoch=980, loss=7.4633\n",
      "(T) | Epoch=990, loss=7.5461\n",
      "(T) | Epoch=1000, loss=7.5094\n",
      "[2025-02-21 13:39:01] \u001b[32mIntermediate result: 0.6138249039649963  (Index 13)\u001b[0m\n",
      "(E) | Epoch=1000, avg_acc = 0.6138249039649963\n",
      "(T) | Epoch=1010, loss=7.4796\n",
      "(T) | Epoch=1020, loss=7.4847\n",
      "(T) | Epoch=1030, loss=7.4840\n",
      "(T) | Epoch=1040, loss=7.4841\n",
      "(T) | Epoch=1050, loss=7.4660\n",
      "(T) | Epoch=1060, loss=7.5019\n",
      "(T) | Epoch=1070, loss=7.4800\n",
      "(T) | Epoch=1080, loss=7.4465\n",
      "(T) | Epoch=1090, loss=7.4626\n",
      "(T) | Epoch=1100, loss=7.4476\n",
      "[2025-02-21 13:39:08] \u001b[32mIntermediate result: 0.6163594722747803  (Index 14)\u001b[0m\n",
      "(E) | Epoch=1100, avg_acc = 0.6163594722747803\n",
      "(T) | Epoch=1110, loss=7.4537\n",
      "(T) | Epoch=1120, loss=7.5182\n",
      "(T) | Epoch=1130, loss=7.5032\n",
      "(T) | Epoch=1140, loss=7.4285\n",
      "(T) | Epoch=1150, loss=7.4833\n",
      "(T) | Epoch=1160, loss=7.4702\n",
      "(T) | Epoch=1170, loss=7.4533\n",
      "(T) | Epoch=1180, loss=7.4643\n",
      "(T) | Epoch=1190, loss=7.4533\n",
      "(T) | Epoch=1200, loss=7.4773\n",
      "[2025-02-21 13:39:16] \u001b[32mIntermediate result: 0.6281105875968933  (Index 15)\u001b[0m\n",
      "(E) | Epoch=1200, avg_acc = 0.6281105875968933\n",
      "(T) | Epoch=1210, loss=7.4243\n",
      "(T) | Epoch=1220, loss=7.4351\n",
      "(T) | Epoch=1230, loss=7.4462\n",
      "(T) | Epoch=1240, loss=7.4306\n",
      "(T) | Epoch=1250, loss=7.4204\n",
      "(T) | Epoch=1260, loss=7.4311\n",
      "(T) | Epoch=1270, loss=7.4540\n",
      "(T) | Epoch=1280, loss=7.4064\n",
      "(T) | Epoch=1290, loss=7.4398\n",
      "(T) | Epoch=1300, loss=7.4446\n",
      "[2025-02-21 13:39:23] \u001b[32mIntermediate result: 0.617511510848999  (Index 16)\u001b[0m\n",
      "(E) | Epoch=1300, avg_acc = 0.617511510848999\n",
      "(T) | Epoch=1310, loss=7.4292\n",
      "(T) | Epoch=1320, loss=7.4269\n",
      "(T) | Epoch=1330, loss=7.4655\n",
      "(T) | Epoch=1340, loss=7.4408\n",
      "(T) | Epoch=1350, loss=7.4623\n",
      "(T) | Epoch=1360, loss=7.4225\n",
      "(T) | Epoch=1370, loss=7.4070\n",
      "(T) | Epoch=1380, loss=7.4392\n",
      "(T) | Epoch=1390, loss=7.3907\n",
      "(T) | Epoch=1400, loss=7.3868\n",
      "[2025-02-21 13:39:31] \u001b[32mIntermediate result: 0.6131336688995361  (Index 17)\u001b[0m\n",
      "(E) | Epoch=1400, avg_acc = 0.6131336688995361\n",
      "(T) | Epoch=1410, loss=7.4047\n",
      "(T) | Epoch=1420, loss=7.3835\n",
      "(T) | Epoch=1430, loss=7.3961\n",
      "(T) | Epoch=1440, loss=7.3760\n",
      "(T) | Epoch=1450, loss=7.4112\n",
      "(T) | Epoch=1460, loss=7.3825\n",
      "(T) | Epoch=1470, loss=7.3897\n",
      "(T) | Epoch=1480, loss=7.3891\n",
      "(T) | Epoch=1490, loss=7.3785\n",
      "(T) | Epoch=1500, loss=7.3937\n",
      "[2025-02-21 13:39:38] \u001b[32mIntermediate result: 0.6043778657913208  (Index 18)\u001b[0m\n",
      "(E) | Epoch=1500, avg_acc = 0.6043778657913208\n",
      "(T) | Epoch=1510, loss=7.4092\n",
      "(T) | Epoch=1520, loss=7.4249\n",
      "(T) | Epoch=1530, loss=7.3591\n",
      "(T) | Epoch=1540, loss=7.3935\n",
      "(T) | Epoch=1550, loss=7.3881\n",
      "(T) | Epoch=1560, loss=7.3869\n",
      "(T) | Epoch=1570, loss=7.3557\n",
      "(T) | Epoch=1580, loss=7.3820\n",
      "(T) | Epoch=1590, loss=7.3618\n",
      "(T) | Epoch=1600, loss=7.3440\n",
      "[2025-02-21 13:39:46] \u001b[32mIntermediate result: 0.5997695922851562  (Index 19)\u001b[0m\n",
      "(E) | Epoch=1600, avg_acc = 0.5997695922851562\n",
      "(T) | Epoch=1610, loss=7.3394\n",
      "(T) | Epoch=1620, loss=7.3447\n",
      "(T) | Epoch=1630, loss=7.3916\n",
      "(T) | Epoch=1640, loss=7.3538\n",
      "(T) | Epoch=1650, loss=7.3536\n",
      "(T) | Epoch=1660, loss=7.3430\n",
      "(T) | Epoch=1670, loss=7.3654\n",
      "(T) | Epoch=1680, loss=7.3685\n",
      "(T) | Epoch=1690, loss=7.3542\n",
      "(T) | Epoch=1700, loss=7.3457\n",
      "[2025-02-21 13:39:54] \u001b[32mIntermediate result: 0.5900921821594238  (Index 20)\u001b[0m\n",
      "(E) | Epoch=1700, avg_acc = 0.5900921821594238\n",
      "(T) | Epoch=1710, loss=7.3388\n",
      "(T) | Epoch=1720, loss=7.3165\n",
      "(T) | Epoch=1730, loss=7.3710\n",
      "(T) | Epoch=1740, loss=7.3497\n",
      "(T) | Epoch=1750, loss=7.3406\n",
      "(T) | Epoch=1760, loss=7.3620\n",
      "(T) | Epoch=1770, loss=7.3384\n",
      "(T) | Epoch=1780, loss=7.3611\n",
      "(T) | Epoch=1790, loss=7.3586\n",
      "(T) | Epoch=1800, loss=7.3425\n",
      "[2025-02-21 13:40:02] \u001b[32mIntermediate result: 0.5845622420310974  (Index 21)\u001b[0m\n",
      "(E) | Epoch=1800, avg_acc = 0.5845622420310974\n",
      "(T) | Epoch=1810, loss=7.3549\n",
      "(T) | Epoch=1820, loss=7.3419\n",
      "(T) | Epoch=1830, loss=7.3570\n",
      "(T) | Epoch=1840, loss=7.3447\n",
      "(T) | Epoch=1850, loss=7.3311\n",
      "(T) | Epoch=1860, loss=7.3319\n",
      "(T) | Epoch=1870, loss=7.3159\n",
      "(T) | Epoch=1880, loss=7.3801\n",
      "(T) | Epoch=1890, loss=7.3356\n",
      "(T) | Epoch=1900, loss=7.3475\n",
      "[2025-02-21 13:40:10] \u001b[32mIntermediate result: 0.617511510848999  (Index 22)\u001b[0m\n",
      "(E) | Epoch=1900, avg_acc = 0.617511510848999\n",
      "(T) | Epoch=1910, loss=7.3520\n",
      "(T) | Epoch=1920, loss=7.3201\n",
      "(T) | Epoch=1930, loss=7.3372\n",
      "(T) | Epoch=1940, loss=7.3306\n",
      "(T) | Epoch=1950, loss=7.3462\n",
      "(T) | Epoch=1960, loss=7.3089\n",
      "(T) | Epoch=1970, loss=7.3457\n",
      "(T) | Epoch=1980, loss=7.3335\n",
      "(T) | Epoch=1990, loss=7.3415\n",
      "(T) | Epoch=2000, loss=7.3195\n",
      "[2025-02-21 13:40:18] \u001b[32mIntermediate result: 0.6103686690330505  (Index 23)\u001b[0m\n",
      "(E) | Epoch=2000, avg_acc = 0.6103686690330505\n",
      "(T) | Epoch=2010, loss=7.2962\n",
      "(T) | Epoch=2020, loss=7.3427\n",
      "(T) | Epoch=2030, loss=7.3124\n",
      "(T) | Epoch=2040, loss=7.3002\n",
      "(T) | Epoch=2050, loss=7.3056\n",
      "(T) | Epoch=2060, loss=7.3282\n",
      "(T) | Epoch=2070, loss=7.3164\n",
      "(T) | Epoch=2080, loss=7.3156\n",
      "(T) | Epoch=2090, loss=7.2786\n",
      "(T) | Epoch=2100, loss=7.3558\n",
      "[2025-02-21 13:40:25] \u001b[32mIntermediate result: 0.6119815707206726  (Index 24)\u001b[0m\n",
      "(E) | Epoch=2100, avg_acc = 0.6119815707206726\n",
      "(T) | Epoch=2110, loss=7.3410\n",
      "(T) | Epoch=2120, loss=7.3180\n",
      "(T) | Epoch=2130, loss=7.3137\n",
      "(T) | Epoch=2140, loss=7.2987\n",
      "(T) | Epoch=2150, loss=7.3305\n",
      "(T) | Epoch=2160, loss=7.2963\n",
      "(T) | Epoch=2170, loss=7.3076\n",
      "(T) | Epoch=2180, loss=7.3066\n",
      "(T) | Epoch=2190, loss=7.3532\n",
      "(T) | Epoch=2200, loss=7.3208\n",
      "[2025-02-21 13:40:32] \u001b[32mIntermediate result: 0.6177419424057007  (Index 25)\u001b[0m\n",
      "(E) | Epoch=2200, avg_acc = 0.6177419424057007\n",
      "(T) | Epoch=2210, loss=7.3256\n",
      "(T) | Epoch=2220, loss=7.3246\n",
      "(T) | Epoch=2230, loss=7.3149\n",
      "(T) | Epoch=2240, loss=7.2862\n",
      "(T) | Epoch=2250, loss=7.2935\n",
      "(T) | Epoch=2260, loss=7.2869\n",
      "(T) | Epoch=2270, loss=7.2732\n",
      "(T) | Epoch=2280, loss=7.3013\n",
      "(T) | Epoch=2290, loss=7.2994\n",
      "(T) | Epoch=2300, loss=7.3006\n",
      "[2025-02-21 13:40:40] \u001b[32mIntermediate result: 0.5997695922851562  (Index 26)\u001b[0m\n",
      "(E) | Epoch=2300, avg_acc = 0.5997695922851562\n",
      "(T) | Epoch=2310, loss=7.2594\n",
      "(T) | Epoch=2320, loss=7.3207\n",
      "(T) | Epoch=2330, loss=7.3013\n",
      "(T) | Epoch=2340, loss=7.2619\n",
      "(T) | Epoch=2350, loss=7.2758\n",
      "(T) | Epoch=2360, loss=7.2554\n",
      "(T) | Epoch=2370, loss=7.2924\n",
      "(T) | Epoch=2380, loss=7.2953\n",
      "(T) | Epoch=2390, loss=7.3461\n",
      "(T) | Epoch=2400, loss=7.2824\n",
      "[2025-02-21 13:40:48] \u001b[32mIntermediate result: 0.6108294725418091  (Index 27)\u001b[0m\n",
      "(E) | Epoch=2400, avg_acc = 0.6108294725418091\n",
      "(T) | Epoch=2410, loss=7.3009\n",
      "(T) | Epoch=2420, loss=7.2718\n",
      "(T) | Epoch=2430, loss=7.3069\n",
      "(T) | Epoch=2440, loss=7.2903\n",
      "(T) | Epoch=2450, loss=7.2848\n",
      "(T) | Epoch=2460, loss=7.2777\n",
      "(T) | Epoch=2470, loss=7.3035\n",
      "(T) | Epoch=2480, loss=7.2490\n",
      "(T) | Epoch=2490, loss=7.2747\n",
      "(T) | Epoch=2500, loss=7.2941\n",
      "[2025-02-21 13:40:55] \u001b[32mIntermediate result: 0.6027649641036987  (Index 28)\u001b[0m\n",
      "(E) | Epoch=2500, avg_acc = 0.6027649641036987\n",
      "(T) | Epoch=2510, loss=7.2615\n",
      "(T) | Epoch=2520, loss=7.2755\n",
      "(T) | Epoch=2530, loss=7.2880\n",
      "(T) | Epoch=2540, loss=7.2888\n",
      "(T) | Epoch=2550, loss=7.3053\n",
      "(T) | Epoch=2560, loss=7.3055\n",
      "(T) | Epoch=2570, loss=7.2792\n",
      "(T) | Epoch=2580, loss=7.3120\n",
      "(T) | Epoch=2590, loss=7.2682\n",
      "(T) | Epoch=2600, loss=7.2707\n",
      "[2025-02-21 13:41:03] \u001b[32mIntermediate result: 0.5937787890434265  (Index 29)\u001b[0m\n",
      "(E) | Epoch=2600, avg_acc = 0.5937787890434265\n",
      "(T) | Epoch=2610, loss=7.3063\n",
      "(T) | Epoch=2620, loss=7.3076\n",
      "(T) | Epoch=2630, loss=7.2810\n",
      "(T) | Epoch=2640, loss=7.2803\n",
      "(T) | Epoch=2650, loss=7.2733\n",
      "(T) | Epoch=2660, loss=7.3063\n",
      "(T) | Epoch=2670, loss=7.3100\n",
      "(T) | Epoch=2680, loss=7.2667\n",
      "(T) | Epoch=2690, loss=7.2355\n",
      "(T) | Epoch=2700, loss=7.2938\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(T) | Epoch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m----> 7\u001b[0m     acc \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(E) | Epoch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m04d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, avg_acc = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(final)\u001b[0m\n\u001b[1;32m      5\u001b[0m z \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m MulticlassEvaluator()\n\u001b[0;32m----> 8\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43mlog_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrand:0.1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreload_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final:\n\u001b[1;32m     11\u001b[0m     nni\u001b[38;5;241m.\u001b[39mreport_final_result(acc)\n",
      "File \u001b[0;32m~/GCL-Link-Prediction/GCA-main/pGRACE/eval.py:64\u001b[0m, in \u001b[0;36mlog_regression\u001b[0;34m(z, data, evaluator, num_epochs, test_device, split, verbose, preload_split)\u001b[0m\n\u001b[1;32m     61\u001b[0m classifier\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     62\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 64\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m[\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m loss \u001b[38;5;241m=\u001b[39m nll_loss(f(output), y[split[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m     67\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/envs/p310/lib/python3.10/site-packages/torch/nn/modules/module.py:1732\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1729\u001b[0m             tracing_state\u001b[38;5;241m.\u001b[39mpop_scope()\n\u001b[1;32m   1730\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_wrapped_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1734\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, param[\"num_epochs\"] + 1):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"(T) | Epoch={epoch:03d}, loss={loss:.4f}\")\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        acc = test()\n",
    "        print(f\"(E) | Epoch={epoch:04d}, avg_acc = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000016d9-ba69-40cf-b4c7-fe3c99c67aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = test()\n",
    "print(f\"{acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jovyan-p310]",
   "language": "python",
   "name": "conda-env-jovyan-p310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
